{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regress√£oKeras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFO8SaCybZmR"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wharrJMSbnGB"
      },
      "source": [
        "concrete = pd.read_csv('https://raw.githubusercontent.com/ncuongce/AI-Machine-Learning/master/Concrete_Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTWhShKdb4kA",
        "outputId": "be56da7d-9668-431c-d9b1-5b3609fdb032"
      },
      "source": [
        "concrete.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Data columns (total 9 columns):\n",
            " #   Column                                                 Non-Null Count  Dtype  \n",
            "---  ------                                                 --------------  -----  \n",
            " 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n",
            " 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n",
            " 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n",
            " 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n",
            " 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n",
            " 7   Age (day)                                              1030 non-null   int64  \n",
            " 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n",
            "dtypes: float64(8), int64(1)\n",
            "memory usage: 72.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW027gkzch7L",
        "outputId": "9576b213-1757-4ad8-ac5b-4576170870d6"
      },
      "source": [
        "concrete[concrete.columns[8]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       79.99\n",
              "1       61.89\n",
              "2       40.27\n",
              "3       41.05\n",
              "4       44.30\n",
              "        ...  \n",
              "1025    44.28\n",
              "1026    31.18\n",
              "1027    23.70\n",
              "1028    32.77\n",
              "1029    32.40\n",
              "Name: Concrete compressive strength(MPa, megapascals) , Length: 1030, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd1JSv1bdH-F"
      },
      "source": [
        "target = concrete[concrete.columns[8]]\n",
        "colnames=['Cement (component 1)(kg in a m^3 mixture)','Blast Furnace Slag (component 2)(kg in a m^3 mixture)','Fly Ash (component 3)(kg in a m^3 mixture)','Water  (component 4)(kg in a m^3 mixture)',\n",
        "'Superplasticizer (component 5)(kg in a m^3 mixture)','Coarse Aggregate  (component 6)(kg in a m^3 mixture)','Fine Aggregate (component 7)(kg in a m^3 mixture)','Age (day)']\n",
        "predictors = concrete[colnames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QARzHgHhZBM"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "vZPGGDJfhdQl",
        "outputId": "8779cb16-7ae6-4b54-b213-ea4615a7c76e"
      },
      "source": [
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
              "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
              "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
              "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
              "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
              "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
              "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
              "      <th>Age (day)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement (component 1)(kg in a m^3 mixture)  ...  Age (day)\n",
              "0                                   2.476712  ...  -0.279597\n",
              "1                                   2.476712  ...  -0.279597\n",
              "2                                   0.491187  ...   3.551340\n",
              "3                                   0.491187  ...   5.055221\n",
              "4                                  -0.790075  ...   4.976069\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCHqgJIlhi1M"
      },
      "source": [
        "n_cols = predictors_norm.shape[1] # number of predictors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fut5qo2ciHyy"
      },
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RvvlUi7iQrh",
        "outputId": "001673e3-2992-4fad-a7e5-917dc26b2c9e"
      },
      "source": [
        "n_cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVvzmpEbiMAz"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam',loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FJWyLWViaHV",
        "outputId": "f76e964b-38cf-4a9a-ffe5-b362e6de6edc"
      },
      "source": [
        "model.fit(predictors_norm,target, epochs = 100, validation_split=0.3, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "23/23 - 0s - loss: 34.9549 - val_loss: 143.8692\n",
            "Epoch 2/1000\n",
            "23/23 - 0s - loss: 34.3712 - val_loss: 144.9846\n",
            "Epoch 3/1000\n",
            "23/23 - 0s - loss: 33.8537 - val_loss: 136.2379\n",
            "Epoch 4/1000\n",
            "23/23 - 0s - loss: 33.5208 - val_loss: 143.1090\n",
            "Epoch 5/1000\n",
            "23/23 - 0s - loss: 33.2942 - val_loss: 135.6778\n",
            "Epoch 6/1000\n",
            "23/23 - 0s - loss: 32.9851 - val_loss: 134.9724\n",
            "Epoch 7/1000\n",
            "23/23 - 0s - loss: 33.1239 - val_loss: 144.7225\n",
            "Epoch 8/1000\n",
            "23/23 - 0s - loss: 32.5363 - val_loss: 146.0588\n",
            "Epoch 9/1000\n",
            "23/23 - 0s - loss: 32.2287 - val_loss: 148.1888\n",
            "Epoch 10/1000\n",
            "23/23 - 0s - loss: 31.7342 - val_loss: 145.4448\n",
            "Epoch 11/1000\n",
            "23/23 - 0s - loss: 31.3162 - val_loss: 136.1758\n",
            "Epoch 12/1000\n",
            "23/23 - 0s - loss: 31.2207 - val_loss: 146.5780\n",
            "Epoch 13/1000\n",
            "23/23 - 0s - loss: 31.2230 - val_loss: 150.6627\n",
            "Epoch 14/1000\n",
            "23/23 - 0s - loss: 30.0739 - val_loss: 138.5489\n",
            "Epoch 15/1000\n",
            "23/23 - 0s - loss: 30.0333 - val_loss: 142.1608\n",
            "Epoch 16/1000\n",
            "23/23 - 0s - loss: 29.7891 - val_loss: 154.2254\n",
            "Epoch 17/1000\n",
            "23/23 - 0s - loss: 30.4245 - val_loss: 146.7976\n",
            "Epoch 18/1000\n",
            "23/23 - 0s - loss: 29.3542 - val_loss: 139.7419\n",
            "Epoch 19/1000\n",
            "23/23 - 0s - loss: 28.9599 - val_loss: 137.5135\n",
            "Epoch 20/1000\n",
            "23/23 - 0s - loss: 28.7109 - val_loss: 142.7410\n",
            "Epoch 21/1000\n",
            "23/23 - 0s - loss: 28.3589 - val_loss: 145.3175\n",
            "Epoch 22/1000\n",
            "23/23 - 0s - loss: 28.0842 - val_loss: 138.8411\n",
            "Epoch 23/1000\n",
            "23/23 - 0s - loss: 27.9019 - val_loss: 137.0564\n",
            "Epoch 24/1000\n",
            "23/23 - 0s - loss: 28.3006 - val_loss: 154.3651\n",
            "Epoch 25/1000\n",
            "23/23 - 0s - loss: 28.3219 - val_loss: 159.9637\n",
            "Epoch 26/1000\n",
            "23/23 - 0s - loss: 27.0825 - val_loss: 135.6624\n",
            "Epoch 27/1000\n",
            "23/23 - 0s - loss: 27.3247 - val_loss: 142.3035\n",
            "Epoch 28/1000\n",
            "23/23 - 0s - loss: 26.9419 - val_loss: 141.6618\n",
            "Epoch 29/1000\n",
            "23/23 - 0s - loss: 26.9840 - val_loss: 142.7055\n",
            "Epoch 30/1000\n",
            "23/23 - 0s - loss: 26.6473 - val_loss: 145.8802\n",
            "Epoch 31/1000\n",
            "23/23 - 0s - loss: 26.1604 - val_loss: 139.4588\n",
            "Epoch 32/1000\n",
            "23/23 - 0s - loss: 25.9241 - val_loss: 147.8054\n",
            "Epoch 33/1000\n",
            "23/23 - 0s - loss: 25.9466 - val_loss: 150.7199\n",
            "Epoch 34/1000\n",
            "23/23 - 0s - loss: 25.6005 - val_loss: 138.1515\n",
            "Epoch 35/1000\n",
            "23/23 - 0s - loss: 25.2939 - val_loss: 146.3355\n",
            "Epoch 36/1000\n",
            "23/23 - 0s - loss: 24.9914 - val_loss: 151.7437\n",
            "Epoch 37/1000\n",
            "23/23 - 0s - loss: 24.8778 - val_loss: 143.9554\n",
            "Epoch 38/1000\n",
            "23/23 - 0s - loss: 24.9804 - val_loss: 149.8220\n",
            "Epoch 39/1000\n",
            "23/23 - 0s - loss: 24.5793 - val_loss: 139.0512\n",
            "Epoch 40/1000\n",
            "23/23 - 0s - loss: 24.3887 - val_loss: 149.4840\n",
            "Epoch 41/1000\n",
            "23/23 - 0s - loss: 24.4771 - val_loss: 138.4843\n",
            "Epoch 42/1000\n",
            "23/23 - 0s - loss: 24.3213 - val_loss: 138.2130\n",
            "Epoch 43/1000\n",
            "23/23 - 0s - loss: 24.4378 - val_loss: 140.1471\n",
            "Epoch 44/1000\n",
            "23/23 - 0s - loss: 23.5911 - val_loss: 152.3204\n",
            "Epoch 45/1000\n",
            "23/23 - 0s - loss: 23.6137 - val_loss: 155.9021\n",
            "Epoch 46/1000\n",
            "23/23 - 0s - loss: 23.2279 - val_loss: 142.7757\n",
            "Epoch 47/1000\n",
            "23/23 - 0s - loss: 23.3207 - val_loss: 148.1765\n",
            "Epoch 48/1000\n",
            "23/23 - 0s - loss: 23.1137 - val_loss: 153.7835\n",
            "Epoch 49/1000\n",
            "23/23 - 0s - loss: 22.7347 - val_loss: 144.2712\n",
            "Epoch 50/1000\n",
            "23/23 - 0s - loss: 22.6383 - val_loss: 136.6310\n",
            "Epoch 51/1000\n",
            "23/23 - 0s - loss: 22.9139 - val_loss: 154.2191\n",
            "Epoch 52/1000\n",
            "23/23 - 0s - loss: 23.1646 - val_loss: 155.5723\n",
            "Epoch 53/1000\n",
            "23/23 - 0s - loss: 22.1741 - val_loss: 145.6096\n",
            "Epoch 54/1000\n",
            "23/23 - 0s - loss: 22.2574 - val_loss: 146.0005\n",
            "Epoch 55/1000\n",
            "23/23 - 0s - loss: 22.0284 - val_loss: 157.1227\n",
            "Epoch 56/1000\n",
            "23/23 - 0s - loss: 22.1383 - val_loss: 145.1960\n",
            "Epoch 57/1000\n",
            "23/23 - 0s - loss: 21.7268 - val_loss: 150.5584\n",
            "Epoch 58/1000\n",
            "23/23 - 0s - loss: 22.3368 - val_loss: 144.2694\n",
            "Epoch 59/1000\n",
            "23/23 - 0s - loss: 21.6870 - val_loss: 149.5659\n",
            "Epoch 60/1000\n",
            "23/23 - 0s - loss: 21.7461 - val_loss: 146.7312\n",
            "Epoch 61/1000\n",
            "23/23 - 0s - loss: 21.0606 - val_loss: 133.4742\n",
            "Epoch 62/1000\n",
            "23/23 - 0s - loss: 21.8458 - val_loss: 146.6092\n",
            "Epoch 63/1000\n",
            "23/23 - 0s - loss: 21.2674 - val_loss: 159.3732\n",
            "Epoch 64/1000\n",
            "23/23 - 0s - loss: 21.1663 - val_loss: 145.5668\n",
            "Epoch 65/1000\n",
            "23/23 - 0s - loss: 20.8645 - val_loss: 147.5630\n",
            "Epoch 66/1000\n",
            "23/23 - 0s - loss: 20.7593 - val_loss: 148.2775\n",
            "Epoch 67/1000\n",
            "23/23 - 0s - loss: 20.5113 - val_loss: 140.6550\n",
            "Epoch 68/1000\n",
            "23/23 - 0s - loss: 20.6810 - val_loss: 153.3071\n",
            "Epoch 69/1000\n",
            "23/23 - 0s - loss: 20.3575 - val_loss: 152.0553\n",
            "Epoch 70/1000\n",
            "23/23 - 0s - loss: 20.2912 - val_loss: 139.7401\n",
            "Epoch 71/1000\n",
            "23/23 - 0s - loss: 20.3515 - val_loss: 145.4235\n",
            "Epoch 72/1000\n",
            "23/23 - 0s - loss: 20.1310 - val_loss: 147.8619\n",
            "Epoch 73/1000\n",
            "23/23 - 0s - loss: 19.8258 - val_loss: 141.6684\n",
            "Epoch 74/1000\n",
            "23/23 - 0s - loss: 19.9127 - val_loss: 146.7025\n",
            "Epoch 75/1000\n",
            "23/23 - 0s - loss: 19.8631 - val_loss: 142.7640\n",
            "Epoch 76/1000\n",
            "23/23 - 0s - loss: 19.5757 - val_loss: 148.2951\n",
            "Epoch 77/1000\n",
            "23/23 - 0s - loss: 19.6240 - val_loss: 145.7492\n",
            "Epoch 78/1000\n",
            "23/23 - 0s - loss: 19.7520 - val_loss: 150.1762\n",
            "Epoch 79/1000\n",
            "23/23 - 0s - loss: 20.2817 - val_loss: 135.5543\n",
            "Epoch 80/1000\n",
            "23/23 - 0s - loss: 19.6335 - val_loss: 148.0027\n",
            "Epoch 81/1000\n",
            "23/23 - 0s - loss: 19.2603 - val_loss: 143.1605\n",
            "Epoch 82/1000\n",
            "23/23 - 0s - loss: 19.6670 - val_loss: 139.4892\n",
            "Epoch 83/1000\n",
            "23/23 - 0s - loss: 19.2509 - val_loss: 147.2970\n",
            "Epoch 84/1000\n",
            "23/23 - 0s - loss: 19.1388 - val_loss: 137.8885\n",
            "Epoch 85/1000\n",
            "23/23 - 0s - loss: 19.3007 - val_loss: 147.5134\n",
            "Epoch 86/1000\n",
            "23/23 - 0s - loss: 18.8985 - val_loss: 143.8347\n",
            "Epoch 87/1000\n",
            "23/23 - 0s - loss: 19.0162 - val_loss: 142.9409\n",
            "Epoch 88/1000\n",
            "23/23 - 0s - loss: 18.8505 - val_loss: 143.6154\n",
            "Epoch 89/1000\n",
            "23/23 - 0s - loss: 18.5902 - val_loss: 137.7592\n",
            "Epoch 90/1000\n",
            "23/23 - 0s - loss: 18.5760 - val_loss: 135.3537\n",
            "Epoch 91/1000\n",
            "23/23 - 0s - loss: 19.4905 - val_loss: 128.8629\n",
            "Epoch 92/1000\n",
            "23/23 - 0s - loss: 18.8167 - val_loss: 133.0091\n",
            "Epoch 93/1000\n",
            "23/23 - 0s - loss: 18.6054 - val_loss: 139.2658\n",
            "Epoch 94/1000\n",
            "23/23 - 0s - loss: 18.3293 - val_loss: 142.7706\n",
            "Epoch 95/1000\n",
            "23/23 - 0s - loss: 18.3333 - val_loss: 133.7114\n",
            "Epoch 96/1000\n",
            "23/23 - 0s - loss: 18.2449 - val_loss: 152.1413\n",
            "Epoch 97/1000\n",
            "23/23 - 0s - loss: 18.2787 - val_loss: 142.5752\n",
            "Epoch 98/1000\n",
            "23/23 - 0s - loss: 17.9395 - val_loss: 146.8426\n",
            "Epoch 99/1000\n",
            "23/23 - 0s - loss: 17.9893 - val_loss: 145.0642\n",
            "Epoch 100/1000\n",
            "23/23 - 0s - loss: 17.7301 - val_loss: 145.9369\n",
            "Epoch 101/1000\n",
            "23/23 - 0s - loss: 17.9177 - val_loss: 148.2840\n",
            "Epoch 102/1000\n",
            "23/23 - 0s - loss: 17.7309 - val_loss: 149.5668\n",
            "Epoch 103/1000\n",
            "23/23 - 0s - loss: 17.5415 - val_loss: 141.0223\n",
            "Epoch 104/1000\n",
            "23/23 - 0s - loss: 18.0315 - val_loss: 129.6447\n",
            "Epoch 105/1000\n",
            "23/23 - 0s - loss: 17.9563 - val_loss: 141.2683\n",
            "Epoch 106/1000\n",
            "23/23 - 0s - loss: 18.4120 - val_loss: 140.8308\n",
            "Epoch 107/1000\n",
            "23/23 - 0s - loss: 17.7686 - val_loss: 145.0893\n",
            "Epoch 108/1000\n",
            "23/23 - 0s - loss: 17.2517 - val_loss: 137.8461\n",
            "Epoch 109/1000\n",
            "23/23 - 0s - loss: 17.0476 - val_loss: 143.6555\n",
            "Epoch 110/1000\n",
            "23/23 - 0s - loss: 17.1178 - val_loss: 139.1086\n",
            "Epoch 111/1000\n",
            "23/23 - 0s - loss: 17.0819 - val_loss: 143.2121\n",
            "Epoch 112/1000\n",
            "23/23 - 0s - loss: 16.8884 - val_loss: 143.0089\n",
            "Epoch 113/1000\n",
            "23/23 - 0s - loss: 16.8220 - val_loss: 139.0132\n",
            "Epoch 114/1000\n",
            "23/23 - 0s - loss: 16.7728 - val_loss: 135.2903\n",
            "Epoch 115/1000\n",
            "23/23 - 0s - loss: 16.8333 - val_loss: 136.9395\n",
            "Epoch 116/1000\n",
            "23/23 - 0s - loss: 17.0448 - val_loss: 130.3747\n",
            "Epoch 117/1000\n",
            "23/23 - 0s - loss: 16.9037 - val_loss: 143.2532\n",
            "Epoch 118/1000\n",
            "23/23 - 0s - loss: 16.6950 - val_loss: 142.1756\n",
            "Epoch 119/1000\n",
            "23/23 - 0s - loss: 17.0477 - val_loss: 139.9222\n",
            "Epoch 120/1000\n",
            "23/23 - 0s - loss: 17.4182 - val_loss: 133.6919\n",
            "Epoch 121/1000\n",
            "23/23 - 0s - loss: 16.6487 - val_loss: 133.7859\n",
            "Epoch 122/1000\n",
            "23/23 - 0s - loss: 16.3522 - val_loss: 142.5822\n",
            "Epoch 123/1000\n",
            "23/23 - 0s - loss: 16.4276 - val_loss: 131.4991\n",
            "Epoch 124/1000\n",
            "23/23 - 0s - loss: 16.6593 - val_loss: 135.8184\n",
            "Epoch 125/1000\n",
            "23/23 - 0s - loss: 16.1292 - val_loss: 137.1095\n",
            "Epoch 126/1000\n",
            "23/23 - 0s - loss: 16.4589 - val_loss: 143.7212\n",
            "Epoch 127/1000\n",
            "23/23 - 0s - loss: 16.5893 - val_loss: 155.7772\n",
            "Epoch 128/1000\n",
            "23/23 - 0s - loss: 17.1864 - val_loss: 141.5154\n",
            "Epoch 129/1000\n",
            "23/23 - 0s - loss: 16.1254 - val_loss: 134.4115\n",
            "Epoch 130/1000\n",
            "23/23 - 0s - loss: 16.1111 - val_loss: 133.6544\n",
            "Epoch 131/1000\n",
            "23/23 - 0s - loss: 16.2605 - val_loss: 131.1148\n",
            "Epoch 132/1000\n",
            "23/23 - 0s - loss: 15.9224 - val_loss: 134.8969\n",
            "Epoch 133/1000\n",
            "23/23 - 0s - loss: 16.0961 - val_loss: 143.3554\n",
            "Epoch 134/1000\n",
            "23/23 - 0s - loss: 15.8245 - val_loss: 133.7178\n",
            "Epoch 135/1000\n",
            "23/23 - 0s - loss: 15.8359 - val_loss: 130.5654\n",
            "Epoch 136/1000\n",
            "23/23 - 0s - loss: 15.9108 - val_loss: 135.4580\n",
            "Epoch 137/1000\n",
            "23/23 - 0s - loss: 16.2218 - val_loss: 137.0294\n",
            "Epoch 138/1000\n",
            "23/23 - 0s - loss: 15.9191 - val_loss: 137.8335\n",
            "Epoch 139/1000\n",
            "23/23 - 0s - loss: 15.7517 - val_loss: 133.3740\n",
            "Epoch 140/1000\n",
            "23/23 - 0s - loss: 15.6105 - val_loss: 141.5094\n",
            "Epoch 141/1000\n",
            "23/23 - 0s - loss: 15.8278 - val_loss: 127.6461\n",
            "Epoch 142/1000\n",
            "23/23 - 0s - loss: 15.3982 - val_loss: 137.5655\n",
            "Epoch 143/1000\n",
            "23/23 - 0s - loss: 15.6193 - val_loss: 143.1802\n",
            "Epoch 144/1000\n",
            "23/23 - 0s - loss: 16.6154 - val_loss: 135.8176\n",
            "Epoch 145/1000\n",
            "23/23 - 0s - loss: 15.6177 - val_loss: 137.4591\n",
            "Epoch 146/1000\n",
            "23/23 - 0s - loss: 15.4957 - val_loss: 136.3261\n",
            "Epoch 147/1000\n",
            "23/23 - 0s - loss: 15.5545 - val_loss: 143.7625\n",
            "Epoch 148/1000\n",
            "23/23 - 0s - loss: 15.5997 - val_loss: 139.1166\n",
            "Epoch 149/1000\n",
            "23/23 - 0s - loss: 15.7334 - val_loss: 142.6410\n",
            "Epoch 150/1000\n",
            "23/23 - 0s - loss: 15.6661 - val_loss: 137.8756\n",
            "Epoch 151/1000\n",
            "23/23 - 0s - loss: 14.9636 - val_loss: 132.1106\n",
            "Epoch 152/1000\n",
            "23/23 - 0s - loss: 15.2459 - val_loss: 133.0893\n",
            "Epoch 153/1000\n",
            "23/23 - 0s - loss: 15.4065 - val_loss: 133.8969\n",
            "Epoch 154/1000\n",
            "23/23 - 0s - loss: 14.9378 - val_loss: 131.4413\n",
            "Epoch 155/1000\n",
            "23/23 - 0s - loss: 14.7949 - val_loss: 138.2624\n",
            "Epoch 156/1000\n",
            "23/23 - 0s - loss: 14.9822 - val_loss: 135.2991\n",
            "Epoch 157/1000\n",
            "23/23 - 0s - loss: 14.8453 - val_loss: 136.9061\n",
            "Epoch 158/1000\n",
            "23/23 - 0s - loss: 14.7453 - val_loss: 132.2646\n",
            "Epoch 159/1000\n",
            "23/23 - 0s - loss: 14.6563 - val_loss: 138.6233\n",
            "Epoch 160/1000\n",
            "23/23 - 0s - loss: 14.7248 - val_loss: 121.4311\n",
            "Epoch 161/1000\n",
            "23/23 - 0s - loss: 15.2597 - val_loss: 127.1079\n",
            "Epoch 162/1000\n",
            "23/23 - 0s - loss: 15.4320 - val_loss: 128.6795\n",
            "Epoch 163/1000\n",
            "23/23 - 0s - loss: 14.6359 - val_loss: 128.0797\n",
            "Epoch 164/1000\n",
            "23/23 - 0s - loss: 14.4742 - val_loss: 132.0868\n",
            "Epoch 165/1000\n",
            "23/23 - 0s - loss: 14.4131 - val_loss: 130.4136\n",
            "Epoch 166/1000\n",
            "23/23 - 0s - loss: 14.1580 - val_loss: 125.5119\n",
            "Epoch 167/1000\n",
            "23/23 - 0s - loss: 14.6836 - val_loss: 121.8992\n",
            "Epoch 168/1000\n",
            "23/23 - 0s - loss: 14.1422 - val_loss: 124.1869\n",
            "Epoch 169/1000\n",
            "23/23 - 0s - loss: 14.4874 - val_loss: 135.4113\n",
            "Epoch 170/1000\n",
            "23/23 - 0s - loss: 14.4950 - val_loss: 132.2285\n",
            "Epoch 171/1000\n",
            "23/23 - 0s - loss: 14.5348 - val_loss: 126.3992\n",
            "Epoch 172/1000\n",
            "23/23 - 0s - loss: 14.2302 - val_loss: 131.2296\n",
            "Epoch 173/1000\n",
            "23/23 - 0s - loss: 14.1834 - val_loss: 131.1191\n",
            "Epoch 174/1000\n",
            "23/23 - 0s - loss: 13.8835 - val_loss: 128.7244\n",
            "Epoch 175/1000\n",
            "23/23 - 0s - loss: 13.9680 - val_loss: 131.7464\n",
            "Epoch 176/1000\n",
            "23/23 - 0s - loss: 14.1061 - val_loss: 126.7274\n",
            "Epoch 177/1000\n",
            "23/23 - 0s - loss: 13.7227 - val_loss: 133.6659\n",
            "Epoch 178/1000\n",
            "23/23 - 0s - loss: 14.0133 - val_loss: 125.8957\n",
            "Epoch 179/1000\n",
            "23/23 - 0s - loss: 13.9013 - val_loss: 128.2969\n",
            "Epoch 180/1000\n",
            "23/23 - 0s - loss: 13.8406 - val_loss: 129.0329\n",
            "Epoch 181/1000\n",
            "23/23 - 0s - loss: 13.7097 - val_loss: 127.0027\n",
            "Epoch 182/1000\n",
            "23/23 - 0s - loss: 13.6578 - val_loss: 125.2832\n",
            "Epoch 183/1000\n",
            "23/23 - 0s - loss: 13.9222 - val_loss: 127.0628\n",
            "Epoch 184/1000\n",
            "23/23 - 0s - loss: 13.4778 - val_loss: 123.3399\n",
            "Epoch 185/1000\n",
            "23/23 - 0s - loss: 13.5823 - val_loss: 135.4302\n",
            "Epoch 186/1000\n",
            "23/23 - 0s - loss: 13.7206 - val_loss: 122.7489\n",
            "Epoch 187/1000\n",
            "23/23 - 0s - loss: 14.1201 - val_loss: 123.1859\n",
            "Epoch 188/1000\n",
            "23/23 - 0s - loss: 13.4063 - val_loss: 132.4352\n",
            "Epoch 189/1000\n",
            "23/23 - 0s - loss: 13.8761 - val_loss: 127.5535\n",
            "Epoch 190/1000\n",
            "23/23 - 0s - loss: 13.7850 - val_loss: 128.9456\n",
            "Epoch 191/1000\n",
            "23/23 - 0s - loss: 13.8934 - val_loss: 123.0098\n",
            "Epoch 192/1000\n",
            "23/23 - 0s - loss: 13.7592 - val_loss: 123.4220\n",
            "Epoch 193/1000\n",
            "23/23 - 0s - loss: 14.5519 - val_loss: 113.0777\n",
            "Epoch 194/1000\n",
            "23/23 - 0s - loss: 14.1774 - val_loss: 122.6467\n",
            "Epoch 195/1000\n",
            "23/23 - 0s - loss: 13.4245 - val_loss: 126.8301\n",
            "Epoch 196/1000\n",
            "23/23 - 0s - loss: 13.3161 - val_loss: 123.3543\n",
            "Epoch 197/1000\n",
            "23/23 - 0s - loss: 13.7010 - val_loss: 121.4899\n",
            "Epoch 198/1000\n",
            "23/23 - 0s - loss: 13.2608 - val_loss: 120.7282\n",
            "Epoch 199/1000\n",
            "23/23 - 0s - loss: 13.2676 - val_loss: 120.5678\n",
            "Epoch 200/1000\n",
            "23/23 - 0s - loss: 13.6051 - val_loss: 119.8643\n",
            "Epoch 201/1000\n",
            "23/23 - 0s - loss: 13.2872 - val_loss: 124.6600\n",
            "Epoch 202/1000\n",
            "23/23 - 0s - loss: 12.9676 - val_loss: 128.1619\n",
            "Epoch 203/1000\n",
            "23/23 - 0s - loss: 12.9830 - val_loss: 123.2744\n",
            "Epoch 204/1000\n",
            "23/23 - 0s - loss: 13.0441 - val_loss: 122.0002\n",
            "Epoch 205/1000\n",
            "23/23 - 0s - loss: 12.8681 - val_loss: 130.5045\n",
            "Epoch 206/1000\n",
            "23/23 - 0s - loss: 13.2283 - val_loss: 125.4850\n",
            "Epoch 207/1000\n",
            "23/23 - 0s - loss: 13.3276 - val_loss: 140.0767\n",
            "Epoch 208/1000\n",
            "23/23 - 0s - loss: 13.4215 - val_loss: 136.5773\n",
            "Epoch 209/1000\n",
            "23/23 - 0s - loss: 12.8635 - val_loss: 120.1327\n",
            "Epoch 210/1000\n",
            "23/23 - 0s - loss: 13.0489 - val_loss: 130.7850\n",
            "Epoch 211/1000\n",
            "23/23 - 0s - loss: 12.7234 - val_loss: 118.6973\n",
            "Epoch 212/1000\n",
            "23/23 - 0s - loss: 12.5757 - val_loss: 119.6833\n",
            "Epoch 213/1000\n",
            "23/23 - 0s - loss: 12.7299 - val_loss: 118.2637\n",
            "Epoch 214/1000\n",
            "23/23 - 0s - loss: 12.7379 - val_loss: 120.5368\n",
            "Epoch 215/1000\n",
            "23/23 - 0s - loss: 12.3576 - val_loss: 124.6452\n",
            "Epoch 216/1000\n",
            "23/23 - 0s - loss: 12.5149 - val_loss: 117.9444\n",
            "Epoch 217/1000\n",
            "23/23 - 0s - loss: 12.8965 - val_loss: 123.8424\n",
            "Epoch 218/1000\n",
            "23/23 - 0s - loss: 12.3861 - val_loss: 123.2915\n",
            "Epoch 219/1000\n",
            "23/23 - 0s - loss: 12.3598 - val_loss: 120.5109\n",
            "Epoch 220/1000\n",
            "23/23 - 0s - loss: 12.7321 - val_loss: 117.4554\n",
            "Epoch 221/1000\n",
            "23/23 - 0s - loss: 12.4997 - val_loss: 122.0826\n",
            "Epoch 222/1000\n",
            "23/23 - 0s - loss: 12.3686 - val_loss: 122.4669\n",
            "Epoch 223/1000\n",
            "23/23 - 0s - loss: 12.3432 - val_loss: 124.7288\n",
            "Epoch 224/1000\n",
            "23/23 - 0s - loss: 12.6589 - val_loss: 126.2553\n",
            "Epoch 225/1000\n",
            "23/23 - 0s - loss: 12.5388 - val_loss: 133.9685\n",
            "Epoch 226/1000\n",
            "23/23 - 0s - loss: 12.3721 - val_loss: 115.3778\n",
            "Epoch 227/1000\n",
            "23/23 - 0s - loss: 12.6123 - val_loss: 127.1903\n",
            "Epoch 228/1000\n",
            "23/23 - 0s - loss: 12.4748 - val_loss: 121.0247\n",
            "Epoch 229/1000\n",
            "23/23 - 0s - loss: 12.3893 - val_loss: 123.9384\n",
            "Epoch 230/1000\n",
            "23/23 - 0s - loss: 12.0917 - val_loss: 124.7686\n",
            "Epoch 231/1000\n",
            "23/23 - 0s - loss: 12.0900 - val_loss: 120.4544\n",
            "Epoch 232/1000\n",
            "23/23 - 0s - loss: 11.9890 - val_loss: 124.3283\n",
            "Epoch 233/1000\n",
            "23/23 - 0s - loss: 11.9451 - val_loss: 117.7839\n",
            "Epoch 234/1000\n",
            "23/23 - 0s - loss: 12.4070 - val_loss: 117.2227\n",
            "Epoch 235/1000\n",
            "23/23 - 0s - loss: 12.0021 - val_loss: 113.6976\n",
            "Epoch 236/1000\n",
            "23/23 - 0s - loss: 12.1211 - val_loss: 125.8627\n",
            "Epoch 237/1000\n",
            "23/23 - 0s - loss: 11.8398 - val_loss: 121.3406\n",
            "Epoch 238/1000\n",
            "23/23 - 0s - loss: 11.8818 - val_loss: 121.0805\n",
            "Epoch 239/1000\n",
            "23/23 - 0s - loss: 11.8501 - val_loss: 120.1380\n",
            "Epoch 240/1000\n",
            "23/23 - 0s - loss: 11.8175 - val_loss: 117.1879\n",
            "Epoch 241/1000\n",
            "23/23 - 0s - loss: 11.6672 - val_loss: 120.4702\n",
            "Epoch 242/1000\n",
            "23/23 - 0s - loss: 12.8890 - val_loss: 110.1288\n",
            "Epoch 243/1000\n",
            "23/23 - 0s - loss: 12.6953 - val_loss: 110.5245\n",
            "Epoch 244/1000\n",
            "23/23 - 0s - loss: 12.3341 - val_loss: 113.2343\n",
            "Epoch 245/1000\n",
            "23/23 - 0s - loss: 11.9074 - val_loss: 121.4341\n",
            "Epoch 246/1000\n",
            "23/23 - 0s - loss: 12.0485 - val_loss: 125.0591\n",
            "Epoch 247/1000\n",
            "23/23 - 0s - loss: 12.0498 - val_loss: 122.0467\n",
            "Epoch 248/1000\n",
            "23/23 - 0s - loss: 11.7298 - val_loss: 114.3574\n",
            "Epoch 249/1000\n",
            "23/23 - 0s - loss: 11.9091 - val_loss: 119.5123\n",
            "Epoch 250/1000\n",
            "23/23 - 0s - loss: 11.5406 - val_loss: 119.5317\n",
            "Epoch 251/1000\n",
            "23/23 - 0s - loss: 11.8881 - val_loss: 111.7003\n",
            "Epoch 252/1000\n",
            "23/23 - 0s - loss: 11.8495 - val_loss: 119.2033\n",
            "Epoch 253/1000\n",
            "23/23 - 0s - loss: 12.1908 - val_loss: 124.6759\n",
            "Epoch 254/1000\n",
            "23/23 - 0s - loss: 11.5208 - val_loss: 117.1088\n",
            "Epoch 255/1000\n",
            "23/23 - 0s - loss: 12.3997 - val_loss: 126.3469\n",
            "Epoch 256/1000\n",
            "23/23 - 0s - loss: 11.5735 - val_loss: 118.4512\n",
            "Epoch 257/1000\n",
            "23/23 - 0s - loss: 11.8266 - val_loss: 115.8189\n",
            "Epoch 258/1000\n",
            "23/23 - 0s - loss: 11.5465 - val_loss: 117.4620\n",
            "Epoch 259/1000\n",
            "23/23 - 0s - loss: 11.3288 - val_loss: 128.9407\n",
            "Epoch 260/1000\n",
            "23/23 - 0s - loss: 12.0024 - val_loss: 125.5263\n",
            "Epoch 261/1000\n",
            "23/23 - 0s - loss: 11.3890 - val_loss: 112.2322\n",
            "Epoch 262/1000\n",
            "23/23 - 0s - loss: 11.1359 - val_loss: 115.8496\n",
            "Epoch 263/1000\n",
            "23/23 - 0s - loss: 11.3731 - val_loss: 119.6364\n",
            "Epoch 264/1000\n",
            "23/23 - 0s - loss: 11.4735 - val_loss: 124.0111\n",
            "Epoch 265/1000\n",
            "23/23 - 0s - loss: 11.3102 - val_loss: 113.6349\n",
            "Epoch 266/1000\n",
            "23/23 - 0s - loss: 11.7625 - val_loss: 116.2612\n",
            "Epoch 267/1000\n",
            "23/23 - 0s - loss: 11.6378 - val_loss: 124.8120\n",
            "Epoch 268/1000\n",
            "23/23 - 0s - loss: 11.7203 - val_loss: 119.8843\n",
            "Epoch 269/1000\n",
            "23/23 - 0s - loss: 11.1319 - val_loss: 118.7926\n",
            "Epoch 270/1000\n",
            "23/23 - 0s - loss: 11.0826 - val_loss: 117.8848\n",
            "Epoch 271/1000\n",
            "23/23 - 0s - loss: 10.9611 - val_loss: 119.1495\n",
            "Epoch 272/1000\n",
            "23/23 - 0s - loss: 11.0468 - val_loss: 113.3809\n",
            "Epoch 273/1000\n",
            "23/23 - 0s - loss: 11.2627 - val_loss: 118.3717\n",
            "Epoch 274/1000\n",
            "23/23 - 0s - loss: 11.4416 - val_loss: 117.7590\n",
            "Epoch 275/1000\n",
            "23/23 - 0s - loss: 11.3558 - val_loss: 119.8571\n",
            "Epoch 276/1000\n",
            "23/23 - 0s - loss: 11.3593 - val_loss: 114.9497\n",
            "Epoch 277/1000\n",
            "23/23 - 0s - loss: 10.8807 - val_loss: 119.7581\n",
            "Epoch 278/1000\n",
            "23/23 - 0s - loss: 11.2378 - val_loss: 119.2301\n",
            "Epoch 279/1000\n",
            "23/23 - 0s - loss: 10.8878 - val_loss: 118.6593\n",
            "Epoch 280/1000\n",
            "23/23 - 0s - loss: 10.9560 - val_loss: 114.2745\n",
            "Epoch 281/1000\n",
            "23/23 - 0s - loss: 11.1459 - val_loss: 124.1947\n",
            "Epoch 282/1000\n",
            "23/23 - 0s - loss: 11.0674 - val_loss: 125.4150\n",
            "Epoch 283/1000\n",
            "23/23 - 0s - loss: 11.0226 - val_loss: 119.7492\n",
            "Epoch 284/1000\n",
            "23/23 - 0s - loss: 11.1765 - val_loss: 123.8570\n",
            "Epoch 285/1000\n",
            "23/23 - 0s - loss: 10.7778 - val_loss: 119.3254\n",
            "Epoch 286/1000\n",
            "23/23 - 0s - loss: 11.1249 - val_loss: 116.5902\n",
            "Epoch 287/1000\n",
            "23/23 - 0s - loss: 10.9272 - val_loss: 118.6380\n",
            "Epoch 288/1000\n",
            "23/23 - 0s - loss: 11.2471 - val_loss: 114.6499\n",
            "Epoch 289/1000\n",
            "23/23 - 0s - loss: 10.9594 - val_loss: 116.1242\n",
            "Epoch 290/1000\n",
            "23/23 - 0s - loss: 10.9901 - val_loss: 118.6285\n",
            "Epoch 291/1000\n",
            "23/23 - 0s - loss: 10.7559 - val_loss: 122.0651\n",
            "Epoch 292/1000\n",
            "23/23 - 0s - loss: 10.7139 - val_loss: 123.8874\n",
            "Epoch 293/1000\n",
            "23/23 - 0s - loss: 11.1764 - val_loss: 121.2172\n",
            "Epoch 294/1000\n",
            "23/23 - 0s - loss: 11.2313 - val_loss: 115.0559\n",
            "Epoch 295/1000\n",
            "23/23 - 0s - loss: 10.9838 - val_loss: 109.9993\n",
            "Epoch 296/1000\n",
            "23/23 - 0s - loss: 11.3853 - val_loss: 106.1917\n",
            "Epoch 297/1000\n",
            "23/23 - 0s - loss: 10.7347 - val_loss: 112.1527\n",
            "Epoch 298/1000\n",
            "23/23 - 0s - loss: 10.8355 - val_loss: 118.0257\n",
            "Epoch 299/1000\n",
            "23/23 - 0s - loss: 10.8795 - val_loss: 125.0006\n",
            "Epoch 300/1000\n",
            "23/23 - 0s - loss: 10.4738 - val_loss: 117.0460\n",
            "Epoch 301/1000\n",
            "23/23 - 0s - loss: 10.8853 - val_loss: 114.3471\n",
            "Epoch 302/1000\n",
            "23/23 - 0s - loss: 11.6287 - val_loss: 114.2931\n",
            "Epoch 303/1000\n",
            "23/23 - 0s - loss: 10.5223 - val_loss: 113.3790\n",
            "Epoch 304/1000\n",
            "23/23 - 0s - loss: 10.5645 - val_loss: 124.8946\n",
            "Epoch 305/1000\n",
            "23/23 - 0s - loss: 11.0985 - val_loss: 118.6514\n",
            "Epoch 306/1000\n",
            "23/23 - 0s - loss: 10.7084 - val_loss: 118.6057\n",
            "Epoch 307/1000\n",
            "23/23 - 0s - loss: 10.5505 - val_loss: 116.7659\n",
            "Epoch 308/1000\n",
            "23/23 - 0s - loss: 10.5180 - val_loss: 127.1140\n",
            "Epoch 309/1000\n",
            "23/23 - 0s - loss: 10.5139 - val_loss: 114.8693\n",
            "Epoch 310/1000\n",
            "23/23 - 0s - loss: 10.7003 - val_loss: 113.8746\n",
            "Epoch 311/1000\n",
            "23/23 - 0s - loss: 10.5263 - val_loss: 115.4561\n",
            "Epoch 312/1000\n",
            "23/23 - 0s - loss: 10.5647 - val_loss: 116.3458\n",
            "Epoch 313/1000\n",
            "23/23 - 0s - loss: 10.3284 - val_loss: 110.2868\n",
            "Epoch 314/1000\n",
            "23/23 - 0s - loss: 10.5436 - val_loss: 115.6566\n",
            "Epoch 315/1000\n",
            "23/23 - 0s - loss: 10.4705 - val_loss: 120.1928\n",
            "Epoch 316/1000\n",
            "23/23 - 0s - loss: 10.3533 - val_loss: 118.5679\n",
            "Epoch 317/1000\n",
            "23/23 - 0s - loss: 10.4934 - val_loss: 110.7188\n",
            "Epoch 318/1000\n",
            "23/23 - 0s - loss: 11.2452 - val_loss: 134.2917\n",
            "Epoch 319/1000\n",
            "23/23 - 0s - loss: 11.3939 - val_loss: 120.9173\n",
            "Epoch 320/1000\n",
            "23/23 - 0s - loss: 10.5514 - val_loss: 117.7360\n",
            "Epoch 321/1000\n",
            "23/23 - 0s - loss: 10.8339 - val_loss: 114.1108\n",
            "Epoch 322/1000\n",
            "23/23 - 0s - loss: 11.0753 - val_loss: 107.6485\n",
            "Epoch 323/1000\n",
            "23/23 - 0s - loss: 10.7626 - val_loss: 119.2608\n",
            "Epoch 324/1000\n",
            "23/23 - 0s - loss: 11.1404 - val_loss: 134.3304\n",
            "Epoch 325/1000\n",
            "23/23 - 0s - loss: 11.1232 - val_loss: 118.9257\n",
            "Epoch 326/1000\n",
            "23/23 - 0s - loss: 10.2641 - val_loss: 114.0919\n",
            "Epoch 327/1000\n",
            "23/23 - 0s - loss: 10.6504 - val_loss: 118.5562\n",
            "Epoch 328/1000\n",
            "23/23 - 0s - loss: 10.1492 - val_loss: 112.4268\n",
            "Epoch 329/1000\n",
            "23/23 - 0s - loss: 10.4795 - val_loss: 124.9017\n",
            "Epoch 330/1000\n",
            "23/23 - 0s - loss: 10.4788 - val_loss: 113.5636\n",
            "Epoch 331/1000\n",
            "23/23 - 0s - loss: 10.2574 - val_loss: 116.6894\n",
            "Epoch 332/1000\n",
            "23/23 - 0s - loss: 10.7315 - val_loss: 116.5404\n",
            "Epoch 333/1000\n",
            "23/23 - 0s - loss: 10.1554 - val_loss: 121.6986\n",
            "Epoch 334/1000\n",
            "23/23 - 0s - loss: 10.2381 - val_loss: 114.8257\n",
            "Epoch 335/1000\n",
            "23/23 - 0s - loss: 10.3188 - val_loss: 125.1971\n",
            "Epoch 336/1000\n",
            "23/23 - 0s - loss: 10.5318 - val_loss: 121.9540\n",
            "Epoch 337/1000\n",
            "23/23 - 0s - loss: 10.1109 - val_loss: 120.8348\n",
            "Epoch 338/1000\n",
            "23/23 - 0s - loss: 10.1552 - val_loss: 127.4652\n",
            "Epoch 339/1000\n",
            "23/23 - 0s - loss: 9.9896 - val_loss: 115.6088\n",
            "Epoch 340/1000\n",
            "23/23 - 0s - loss: 10.1138 - val_loss: 117.6901\n",
            "Epoch 341/1000\n",
            "23/23 - 0s - loss: 9.9618 - val_loss: 129.3347\n",
            "Epoch 342/1000\n",
            "23/23 - 0s - loss: 10.4616 - val_loss: 117.6294\n",
            "Epoch 343/1000\n",
            "23/23 - 0s - loss: 9.9026 - val_loss: 119.4465\n",
            "Epoch 344/1000\n",
            "23/23 - 0s - loss: 9.8614 - val_loss: 118.2624\n",
            "Epoch 345/1000\n",
            "23/23 - 0s - loss: 10.2910 - val_loss: 121.3235\n",
            "Epoch 346/1000\n",
            "23/23 - 0s - loss: 10.4003 - val_loss: 123.5828\n",
            "Epoch 347/1000\n",
            "23/23 - 0s - loss: 10.6136 - val_loss: 108.0637\n",
            "Epoch 348/1000\n",
            "23/23 - 0s - loss: 10.3624 - val_loss: 111.3525\n",
            "Epoch 349/1000\n",
            "23/23 - 0s - loss: 10.9305 - val_loss: 122.6101\n",
            "Epoch 350/1000\n",
            "23/23 - 0s - loss: 10.7647 - val_loss: 119.9562\n",
            "Epoch 351/1000\n",
            "23/23 - 0s - loss: 9.6696 - val_loss: 113.0930\n",
            "Epoch 352/1000\n",
            "23/23 - 0s - loss: 9.8392 - val_loss: 116.2631\n",
            "Epoch 353/1000\n",
            "23/23 - 0s - loss: 9.9435 - val_loss: 112.9537\n",
            "Epoch 354/1000\n",
            "23/23 - 0s - loss: 9.9169 - val_loss: 115.5241\n",
            "Epoch 355/1000\n",
            "23/23 - 0s - loss: 9.7710 - val_loss: 119.1905\n",
            "Epoch 356/1000\n",
            "23/23 - 0s - loss: 10.1108 - val_loss: 109.6092\n",
            "Epoch 357/1000\n",
            "23/23 - 0s - loss: 10.2572 - val_loss: 109.7001\n",
            "Epoch 358/1000\n",
            "23/23 - 0s - loss: 10.3644 - val_loss: 118.5511\n",
            "Epoch 359/1000\n",
            "23/23 - 0s - loss: 10.0716 - val_loss: 112.1144\n",
            "Epoch 360/1000\n",
            "23/23 - 0s - loss: 10.0765 - val_loss: 115.3972\n",
            "Epoch 361/1000\n",
            "23/23 - 0s - loss: 10.0015 - val_loss: 121.6154\n",
            "Epoch 362/1000\n",
            "23/23 - 0s - loss: 10.3544 - val_loss: 117.9726\n",
            "Epoch 363/1000\n",
            "23/23 - 0s - loss: 9.7155 - val_loss: 120.2206\n",
            "Epoch 364/1000\n",
            "23/23 - 0s - loss: 9.6809 - val_loss: 118.1870\n",
            "Epoch 365/1000\n",
            "23/23 - 0s - loss: 9.9529 - val_loss: 113.5639\n",
            "Epoch 366/1000\n",
            "23/23 - 0s - loss: 9.7180 - val_loss: 114.3240\n",
            "Epoch 367/1000\n",
            "23/23 - 0s - loss: 10.5998 - val_loss: 110.8951\n",
            "Epoch 368/1000\n",
            "23/23 - 0s - loss: 9.7371 - val_loss: 118.1873\n",
            "Epoch 369/1000\n",
            "23/23 - 0s - loss: 9.5407 - val_loss: 109.8652\n",
            "Epoch 370/1000\n",
            "23/23 - 0s - loss: 9.7039 - val_loss: 118.3990\n",
            "Epoch 371/1000\n",
            "23/23 - 0s - loss: 9.8884 - val_loss: 114.3655\n",
            "Epoch 372/1000\n",
            "23/23 - 0s - loss: 9.6713 - val_loss: 111.8426\n",
            "Epoch 373/1000\n",
            "23/23 - 0s - loss: 9.8713 - val_loss: 111.0689\n",
            "Epoch 374/1000\n",
            "23/23 - 0s - loss: 9.9767 - val_loss: 113.5394\n",
            "Epoch 375/1000\n",
            "23/23 - 0s - loss: 9.7741 - val_loss: 121.2480\n",
            "Epoch 376/1000\n",
            "23/23 - 0s - loss: 9.7660 - val_loss: 117.1710\n",
            "Epoch 377/1000\n",
            "23/23 - 0s - loss: 9.6388 - val_loss: 114.5532\n",
            "Epoch 378/1000\n",
            "23/23 - 0s - loss: 9.8286 - val_loss: 116.5044\n",
            "Epoch 379/1000\n",
            "23/23 - 0s - loss: 9.9140 - val_loss: 112.6002\n",
            "Epoch 380/1000\n",
            "23/23 - 0s - loss: 9.7099 - val_loss: 112.5825\n",
            "Epoch 381/1000\n",
            "23/23 - 0s - loss: 9.8569 - val_loss: 115.3126\n",
            "Epoch 382/1000\n",
            "23/23 - 0s - loss: 9.4958 - val_loss: 112.7862\n",
            "Epoch 383/1000\n",
            "23/23 - 0s - loss: 9.6117 - val_loss: 105.0503\n",
            "Epoch 384/1000\n",
            "23/23 - 0s - loss: 10.0400 - val_loss: 110.0666\n",
            "Epoch 385/1000\n",
            "23/23 - 0s - loss: 9.8801 - val_loss: 106.0854\n",
            "Epoch 386/1000\n",
            "23/23 - 0s - loss: 9.8607 - val_loss: 114.5655\n",
            "Epoch 387/1000\n",
            "23/23 - 0s - loss: 9.3886 - val_loss: 113.0178\n",
            "Epoch 388/1000\n",
            "23/23 - 0s - loss: 9.6773 - val_loss: 113.7315\n",
            "Epoch 389/1000\n",
            "23/23 - 0s - loss: 9.4550 - val_loss: 115.2450\n",
            "Epoch 390/1000\n",
            "23/23 - 0s - loss: 9.4954 - val_loss: 115.0770\n",
            "Epoch 391/1000\n",
            "23/23 - 0s - loss: 9.3688 - val_loss: 116.3260\n",
            "Epoch 392/1000\n",
            "23/23 - 0s - loss: 9.4709 - val_loss: 120.8051\n",
            "Epoch 393/1000\n",
            "23/23 - 0s - loss: 9.4450 - val_loss: 118.9000\n",
            "Epoch 394/1000\n",
            "23/23 - 0s - loss: 9.3182 - val_loss: 109.8268\n",
            "Epoch 395/1000\n",
            "23/23 - 0s - loss: 9.4046 - val_loss: 111.0587\n",
            "Epoch 396/1000\n",
            "23/23 - 0s - loss: 10.0134 - val_loss: 119.5008\n",
            "Epoch 397/1000\n",
            "23/23 - 0s - loss: 9.5163 - val_loss: 114.8794\n",
            "Epoch 398/1000\n",
            "23/23 - 0s - loss: 9.4502 - val_loss: 109.1490\n",
            "Epoch 399/1000\n",
            "23/23 - 0s - loss: 9.4597 - val_loss: 116.4895\n",
            "Epoch 400/1000\n",
            "23/23 - 0s - loss: 9.5527 - val_loss: 115.9876\n",
            "Epoch 401/1000\n",
            "23/23 - 0s - loss: 9.3250 - val_loss: 112.1486\n",
            "Epoch 402/1000\n",
            "23/23 - 0s - loss: 9.2833 - val_loss: 112.3429\n",
            "Epoch 403/1000\n",
            "23/23 - 0s - loss: 9.3991 - val_loss: 104.7782\n",
            "Epoch 404/1000\n",
            "23/23 - 0s - loss: 9.7562 - val_loss: 110.4028\n",
            "Epoch 405/1000\n",
            "23/23 - 0s - loss: 10.0899 - val_loss: 127.6984\n",
            "Epoch 406/1000\n",
            "23/23 - 0s - loss: 9.6428 - val_loss: 120.2731\n",
            "Epoch 407/1000\n",
            "23/23 - 0s - loss: 9.6985 - val_loss: 117.0219\n",
            "Epoch 408/1000\n",
            "23/23 - 0s - loss: 9.4385 - val_loss: 109.6582\n",
            "Epoch 409/1000\n",
            "23/23 - 0s - loss: 9.5976 - val_loss: 113.8079\n",
            "Epoch 410/1000\n",
            "23/23 - 0s - loss: 9.3961 - val_loss: 106.5891\n",
            "Epoch 411/1000\n",
            "23/23 - 0s - loss: 9.9590 - val_loss: 108.1614\n",
            "Epoch 412/1000\n",
            "23/23 - 0s - loss: 9.9575 - val_loss: 108.4435\n",
            "Epoch 413/1000\n",
            "23/23 - 0s - loss: 9.4480 - val_loss: 111.9933\n",
            "Epoch 414/1000\n",
            "23/23 - 0s - loss: 9.3241 - val_loss: 115.6918\n",
            "Epoch 415/1000\n",
            "23/23 - 0s - loss: 9.7224 - val_loss: 124.2297\n",
            "Epoch 416/1000\n",
            "23/23 - 0s - loss: 9.8112 - val_loss: 115.6475\n",
            "Epoch 417/1000\n",
            "23/23 - 0s - loss: 9.1383 - val_loss: 118.5211\n",
            "Epoch 418/1000\n",
            "23/23 - 0s - loss: 9.1537 - val_loss: 115.1590\n",
            "Epoch 419/1000\n",
            "23/23 - 0s - loss: 9.2191 - val_loss: 118.2923\n",
            "Epoch 420/1000\n",
            "23/23 - 0s - loss: 9.0824 - val_loss: 117.8209\n",
            "Epoch 421/1000\n",
            "23/23 - 0s - loss: 9.3719 - val_loss: 111.4838\n",
            "Epoch 422/1000\n",
            "23/23 - 0s - loss: 9.4588 - val_loss: 111.9096\n",
            "Epoch 423/1000\n",
            "23/23 - 0s - loss: 9.2199 - val_loss: 112.8248\n",
            "Epoch 424/1000\n",
            "23/23 - 0s - loss: 9.5397 - val_loss: 109.5065\n",
            "Epoch 425/1000\n",
            "23/23 - 0s - loss: 9.6415 - val_loss: 115.9045\n",
            "Epoch 426/1000\n",
            "23/23 - 0s - loss: 9.1375 - val_loss: 114.6017\n",
            "Epoch 427/1000\n",
            "23/23 - 0s - loss: 9.3504 - val_loss: 119.8439\n",
            "Epoch 428/1000\n",
            "23/23 - 0s - loss: 9.0305 - val_loss: 113.4361\n",
            "Epoch 429/1000\n",
            "23/23 - 0s - loss: 9.2961 - val_loss: 114.7953\n",
            "Epoch 430/1000\n",
            "23/23 - 0s - loss: 9.3306 - val_loss: 111.9208\n",
            "Epoch 431/1000\n",
            "23/23 - 0s - loss: 9.1924 - val_loss: 113.9531\n",
            "Epoch 432/1000\n",
            "23/23 - 0s - loss: 9.4606 - val_loss: 116.5282\n",
            "Epoch 433/1000\n",
            "23/23 - 0s - loss: 9.0911 - val_loss: 115.8297\n",
            "Epoch 434/1000\n",
            "23/23 - 0s - loss: 9.0247 - val_loss: 112.9754\n",
            "Epoch 435/1000\n",
            "23/23 - 0s - loss: 9.4314 - val_loss: 116.6197\n",
            "Epoch 436/1000\n",
            "23/23 - 0s - loss: 9.1591 - val_loss: 108.6969\n",
            "Epoch 437/1000\n",
            "23/23 - 0s - loss: 9.0621 - val_loss: 115.2472\n",
            "Epoch 438/1000\n",
            "23/23 - 0s - loss: 9.0118 - val_loss: 113.5477\n",
            "Epoch 439/1000\n",
            "23/23 - 0s - loss: 8.8840 - val_loss: 112.5441\n",
            "Epoch 440/1000\n",
            "23/23 - 0s - loss: 9.1793 - val_loss: 111.4934\n",
            "Epoch 441/1000\n",
            "23/23 - 0s - loss: 9.4019 - val_loss: 115.5321\n",
            "Epoch 442/1000\n",
            "23/23 - 0s - loss: 9.3425 - val_loss: 116.2579\n",
            "Epoch 443/1000\n",
            "23/23 - 0s - loss: 9.2881 - val_loss: 114.4904\n",
            "Epoch 444/1000\n",
            "23/23 - 0s - loss: 9.2325 - val_loss: 114.4566\n",
            "Epoch 445/1000\n",
            "23/23 - 0s - loss: 9.4015 - val_loss: 111.9359\n",
            "Epoch 446/1000\n",
            "23/23 - 0s - loss: 8.8962 - val_loss: 110.5755\n",
            "Epoch 447/1000\n",
            "23/23 - 0s - loss: 9.4353 - val_loss: 112.8670\n",
            "Epoch 448/1000\n",
            "23/23 - 0s - loss: 9.0588 - val_loss: 115.4691\n",
            "Epoch 449/1000\n",
            "23/23 - 0s - loss: 9.3330 - val_loss: 118.7163\n",
            "Epoch 450/1000\n",
            "23/23 - 0s - loss: 9.0280 - val_loss: 113.7326\n",
            "Epoch 451/1000\n",
            "23/23 - 0s - loss: 8.9786 - val_loss: 112.2689\n",
            "Epoch 452/1000\n",
            "23/23 - 0s - loss: 9.2552 - val_loss: 115.2817\n",
            "Epoch 453/1000\n",
            "23/23 - 0s - loss: 10.2066 - val_loss: 119.6836\n",
            "Epoch 454/1000\n",
            "23/23 - 0s - loss: 9.2705 - val_loss: 114.2693\n",
            "Epoch 455/1000\n",
            "23/23 - 0s - loss: 9.1212 - val_loss: 120.5537\n",
            "Epoch 456/1000\n",
            "23/23 - 0s - loss: 9.2611 - val_loss: 116.5329\n",
            "Epoch 457/1000\n",
            "23/23 - 0s - loss: 9.2222 - val_loss: 118.5933\n",
            "Epoch 458/1000\n",
            "23/23 - 0s - loss: 9.2088 - val_loss: 115.2607\n",
            "Epoch 459/1000\n",
            "23/23 - 0s - loss: 9.2512 - val_loss: 116.2494\n",
            "Epoch 460/1000\n",
            "23/23 - 0s - loss: 9.2047 - val_loss: 111.2468\n",
            "Epoch 461/1000\n",
            "23/23 - 0s - loss: 8.9484 - val_loss: 110.3805\n",
            "Epoch 462/1000\n",
            "23/23 - 0s - loss: 8.8211 - val_loss: 112.1714\n",
            "Epoch 463/1000\n",
            "23/23 - 0s - loss: 9.1268 - val_loss: 118.6971\n",
            "Epoch 464/1000\n",
            "23/23 - 0s - loss: 8.7405 - val_loss: 115.2622\n",
            "Epoch 465/1000\n",
            "23/23 - 0s - loss: 8.8755 - val_loss: 118.6233\n",
            "Epoch 466/1000\n",
            "23/23 - 0s - loss: 8.8007 - val_loss: 114.5769\n",
            "Epoch 467/1000\n",
            "23/23 - 0s - loss: 9.0756 - val_loss: 109.4748\n",
            "Epoch 468/1000\n",
            "23/23 - 0s - loss: 9.1172 - val_loss: 118.6199\n",
            "Epoch 469/1000\n",
            "23/23 - 0s - loss: 9.3167 - val_loss: 120.2063\n",
            "Epoch 470/1000\n",
            "23/23 - 0s - loss: 9.2498 - val_loss: 110.1559\n",
            "Epoch 471/1000\n",
            "23/23 - 0s - loss: 10.1636 - val_loss: 115.9380\n",
            "Epoch 472/1000\n",
            "23/23 - 0s - loss: 9.2688 - val_loss: 115.5953\n",
            "Epoch 473/1000\n",
            "23/23 - 0s - loss: 8.9569 - val_loss: 112.5658\n",
            "Epoch 474/1000\n",
            "23/23 - 0s - loss: 8.7129 - val_loss: 112.4801\n",
            "Epoch 475/1000\n",
            "23/23 - 0s - loss: 9.1015 - val_loss: 112.4336\n",
            "Epoch 476/1000\n",
            "23/23 - 0s - loss: 9.2831 - val_loss: 117.6679\n",
            "Epoch 477/1000\n",
            "23/23 - 0s - loss: 8.9900 - val_loss: 118.0152\n",
            "Epoch 478/1000\n",
            "23/23 - 0s - loss: 8.9456 - val_loss: 106.2853\n",
            "Epoch 479/1000\n",
            "23/23 - 0s - loss: 9.0426 - val_loss: 113.3085\n",
            "Epoch 480/1000\n",
            "23/23 - 0s - loss: 8.7804 - val_loss: 115.8931\n",
            "Epoch 481/1000\n",
            "23/23 - 0s - loss: 8.7039 - val_loss: 109.0102\n",
            "Epoch 482/1000\n",
            "23/23 - 0s - loss: 9.3599 - val_loss: 108.5966\n",
            "Epoch 483/1000\n",
            "23/23 - 0s - loss: 8.9659 - val_loss: 115.7721\n",
            "Epoch 484/1000\n",
            "23/23 - 0s - loss: 8.7547 - val_loss: 113.5337\n",
            "Epoch 485/1000\n",
            "23/23 - 0s - loss: 8.7292 - val_loss: 113.6026\n",
            "Epoch 486/1000\n",
            "23/23 - 0s - loss: 8.8869 - val_loss: 121.0547\n",
            "Epoch 487/1000\n",
            "23/23 - 0s - loss: 8.6002 - val_loss: 108.4659\n",
            "Epoch 488/1000\n",
            "23/23 - 0s - loss: 8.7580 - val_loss: 118.9269\n",
            "Epoch 489/1000\n",
            "23/23 - 0s - loss: 8.5910 - val_loss: 112.3187\n",
            "Epoch 490/1000\n",
            "23/23 - 0s - loss: 8.7699 - val_loss: 120.8980\n",
            "Epoch 491/1000\n",
            "23/23 - 0s - loss: 8.7501 - val_loss: 117.6192\n",
            "Epoch 492/1000\n",
            "23/23 - 0s - loss: 8.4332 - val_loss: 114.3923\n",
            "Epoch 493/1000\n",
            "23/23 - 0s - loss: 8.9289 - val_loss: 128.5121\n",
            "Epoch 494/1000\n",
            "23/23 - 0s - loss: 9.0319 - val_loss: 113.4552\n",
            "Epoch 495/1000\n",
            "23/23 - 0s - loss: 8.5289 - val_loss: 120.9853\n",
            "Epoch 496/1000\n",
            "23/23 - 0s - loss: 8.7749 - val_loss: 117.5799\n",
            "Epoch 497/1000\n",
            "23/23 - 0s - loss: 9.0532 - val_loss: 122.6468\n",
            "Epoch 498/1000\n",
            "23/23 - 0s - loss: 8.4437 - val_loss: 112.5220\n",
            "Epoch 499/1000\n",
            "23/23 - 0s - loss: 8.7165 - val_loss: 117.8703\n",
            "Epoch 500/1000\n",
            "23/23 - 0s - loss: 8.5024 - val_loss: 123.8178\n",
            "Epoch 501/1000\n",
            "23/23 - 0s - loss: 8.8926 - val_loss: 118.3305\n",
            "Epoch 502/1000\n",
            "23/23 - 0s - loss: 8.9993 - val_loss: 121.4892\n",
            "Epoch 503/1000\n",
            "23/23 - 0s - loss: 8.8172 - val_loss: 113.5326\n",
            "Epoch 504/1000\n",
            "23/23 - 0s - loss: 8.8855 - val_loss: 109.0338\n",
            "Epoch 505/1000\n",
            "23/23 - 0s - loss: 8.6453 - val_loss: 114.7585\n",
            "Epoch 506/1000\n",
            "23/23 - 0s - loss: 8.4048 - val_loss: 112.2289\n",
            "Epoch 507/1000\n",
            "23/23 - 0s - loss: 8.9139 - val_loss: 124.9406\n",
            "Epoch 508/1000\n",
            "23/23 - 0s - loss: 8.5919 - val_loss: 115.2824\n",
            "Epoch 509/1000\n",
            "23/23 - 0s - loss: 8.5007 - val_loss: 122.4401\n",
            "Epoch 510/1000\n",
            "23/23 - 0s - loss: 8.6777 - val_loss: 108.6583\n",
            "Epoch 511/1000\n",
            "23/23 - 0s - loss: 8.5478 - val_loss: 118.1626\n",
            "Epoch 512/1000\n",
            "23/23 - 0s - loss: 8.5747 - val_loss: 118.0701\n",
            "Epoch 513/1000\n",
            "23/23 - 0s - loss: 8.4192 - val_loss: 119.3225\n",
            "Epoch 514/1000\n",
            "23/23 - 0s - loss: 8.4280 - val_loss: 123.0261\n",
            "Epoch 515/1000\n",
            "23/23 - 0s - loss: 8.4385 - val_loss: 120.6669\n",
            "Epoch 516/1000\n",
            "23/23 - 0s - loss: 8.4706 - val_loss: 116.3281\n",
            "Epoch 517/1000\n",
            "23/23 - 0s - loss: 8.5846 - val_loss: 111.6906\n",
            "Epoch 518/1000\n",
            "23/23 - 0s - loss: 8.3697 - val_loss: 118.3354\n",
            "Epoch 519/1000\n",
            "23/23 - 0s - loss: 8.9242 - val_loss: 115.1462\n",
            "Epoch 520/1000\n",
            "23/23 - 0s - loss: 8.4715 - val_loss: 123.4909\n",
            "Epoch 521/1000\n",
            "23/23 - 0s - loss: 8.6340 - val_loss: 114.2807\n",
            "Epoch 522/1000\n",
            "23/23 - 0s - loss: 8.6416 - val_loss: 114.6092\n",
            "Epoch 523/1000\n",
            "23/23 - 0s - loss: 8.3058 - val_loss: 110.0982\n",
            "Epoch 524/1000\n",
            "23/23 - 0s - loss: 8.3381 - val_loss: 117.1358\n",
            "Epoch 525/1000\n",
            "23/23 - 0s - loss: 8.4421 - val_loss: 117.1644\n",
            "Epoch 526/1000\n",
            "23/23 - 0s - loss: 8.0695 - val_loss: 108.2900\n",
            "Epoch 527/1000\n",
            "23/23 - 0s - loss: 8.6118 - val_loss: 122.3640\n",
            "Epoch 528/1000\n",
            "23/23 - 0s - loss: 8.8171 - val_loss: 119.7332\n",
            "Epoch 529/1000\n",
            "23/23 - 0s - loss: 8.2736 - val_loss: 117.2365\n",
            "Epoch 530/1000\n",
            "23/23 - 0s - loss: 9.0038 - val_loss: 113.6432\n",
            "Epoch 531/1000\n",
            "23/23 - 0s - loss: 8.4173 - val_loss: 117.6193\n",
            "Epoch 532/1000\n",
            "23/23 - 0s - loss: 8.4790 - val_loss: 120.3666\n",
            "Epoch 533/1000\n",
            "23/23 - 0s - loss: 8.3397 - val_loss: 117.9541\n",
            "Epoch 534/1000\n",
            "23/23 - 0s - loss: 8.3126 - val_loss: 113.6526\n",
            "Epoch 535/1000\n",
            "23/23 - 0s - loss: 8.5071 - val_loss: 119.5401\n",
            "Epoch 536/1000\n",
            "23/23 - 0s - loss: 8.5675 - val_loss: 118.0719\n",
            "Epoch 537/1000\n",
            "23/23 - 0s - loss: 8.2042 - val_loss: 119.3273\n",
            "Epoch 538/1000\n",
            "23/23 - 0s - loss: 8.3634 - val_loss: 111.7110\n",
            "Epoch 539/1000\n",
            "23/23 - 0s - loss: 8.6304 - val_loss: 115.5789\n",
            "Epoch 540/1000\n",
            "23/23 - 0s - loss: 8.4962 - val_loss: 114.1050\n",
            "Epoch 541/1000\n",
            "23/23 - 0s - loss: 8.3955 - val_loss: 119.4015\n",
            "Epoch 542/1000\n",
            "23/23 - 0s - loss: 8.1563 - val_loss: 115.1656\n",
            "Epoch 543/1000\n",
            "23/23 - 0s - loss: 8.3753 - val_loss: 114.6122\n",
            "Epoch 544/1000\n",
            "23/23 - 0s - loss: 8.2006 - val_loss: 123.8533\n",
            "Epoch 545/1000\n",
            "23/23 - 0s - loss: 8.3640 - val_loss: 110.2501\n",
            "Epoch 546/1000\n",
            "23/23 - 0s - loss: 8.3882 - val_loss: 117.1219\n",
            "Epoch 547/1000\n",
            "23/23 - 0s - loss: 8.1501 - val_loss: 120.3906\n",
            "Epoch 548/1000\n",
            "23/23 - 0s - loss: 8.3060 - val_loss: 118.7761\n",
            "Epoch 549/1000\n",
            "23/23 - 0s - loss: 8.3073 - val_loss: 118.7422\n",
            "Epoch 550/1000\n",
            "23/23 - 0s - loss: 8.5099 - val_loss: 118.8459\n",
            "Epoch 551/1000\n",
            "23/23 - 0s - loss: 8.3824 - val_loss: 118.4580\n",
            "Epoch 552/1000\n",
            "23/23 - 0s - loss: 8.0652 - val_loss: 113.0190\n",
            "Epoch 553/1000\n",
            "23/23 - 0s - loss: 8.4006 - val_loss: 113.8691\n",
            "Epoch 554/1000\n",
            "23/23 - 0s - loss: 8.3647 - val_loss: 119.3336\n",
            "Epoch 555/1000\n",
            "23/23 - 0s - loss: 8.4353 - val_loss: 122.4162\n",
            "Epoch 556/1000\n",
            "23/23 - 0s - loss: 8.1860 - val_loss: 121.0385\n",
            "Epoch 557/1000\n",
            "23/23 - 0s - loss: 8.1869 - val_loss: 116.3372\n",
            "Epoch 558/1000\n",
            "23/23 - 0s - loss: 8.2597 - val_loss: 122.1180\n",
            "Epoch 559/1000\n",
            "23/23 - 0s - loss: 8.4889 - val_loss: 121.8602\n",
            "Epoch 560/1000\n",
            "23/23 - 0s - loss: 8.4960 - val_loss: 111.7854\n",
            "Epoch 561/1000\n",
            "23/23 - 0s - loss: 8.3132 - val_loss: 122.7565\n",
            "Epoch 562/1000\n",
            "23/23 - 0s - loss: 7.9239 - val_loss: 117.3780\n",
            "Epoch 563/1000\n",
            "23/23 - 0s - loss: 8.4487 - val_loss: 120.4294\n",
            "Epoch 564/1000\n",
            "23/23 - 0s - loss: 8.1182 - val_loss: 124.3405\n",
            "Epoch 565/1000\n",
            "23/23 - 0s - loss: 8.5543 - val_loss: 117.4419\n",
            "Epoch 566/1000\n",
            "23/23 - 0s - loss: 8.4804 - val_loss: 113.5622\n",
            "Epoch 567/1000\n",
            "23/23 - 0s - loss: 8.0233 - val_loss: 116.7564\n",
            "Epoch 568/1000\n",
            "23/23 - 0s - loss: 7.8898 - val_loss: 121.5426\n",
            "Epoch 569/1000\n",
            "23/23 - 0s - loss: 8.1925 - val_loss: 119.0298\n",
            "Epoch 570/1000\n",
            "23/23 - 0s - loss: 8.3798 - val_loss: 120.9144\n",
            "Epoch 571/1000\n",
            "23/23 - 0s - loss: 8.1497 - val_loss: 119.5481\n",
            "Epoch 572/1000\n",
            "23/23 - 0s - loss: 8.0700 - val_loss: 115.2889\n",
            "Epoch 573/1000\n",
            "23/23 - 0s - loss: 8.2257 - val_loss: 116.8805\n",
            "Epoch 574/1000\n",
            "23/23 - 0s - loss: 8.4191 - val_loss: 109.4389\n",
            "Epoch 575/1000\n",
            "23/23 - 0s - loss: 8.1595 - val_loss: 114.3968\n",
            "Epoch 576/1000\n",
            "23/23 - 0s - loss: 7.9502 - val_loss: 114.1046\n",
            "Epoch 577/1000\n",
            "23/23 - 0s - loss: 7.7782 - val_loss: 123.4255\n",
            "Epoch 578/1000\n",
            "23/23 - 0s - loss: 8.0468 - val_loss: 115.4893\n",
            "Epoch 579/1000\n",
            "23/23 - 0s - loss: 8.2396 - val_loss: 112.4910\n",
            "Epoch 580/1000\n",
            "23/23 - 0s - loss: 8.5930 - val_loss: 117.6852\n",
            "Epoch 581/1000\n",
            "23/23 - 0s - loss: 8.2515 - val_loss: 119.0551\n",
            "Epoch 582/1000\n",
            "23/23 - 0s - loss: 7.9968 - val_loss: 115.2275\n",
            "Epoch 583/1000\n",
            "23/23 - 0s - loss: 7.9394 - val_loss: 116.0481\n",
            "Epoch 584/1000\n",
            "23/23 - 0s - loss: 8.3567 - val_loss: 125.1961\n",
            "Epoch 585/1000\n",
            "23/23 - 0s - loss: 8.1842 - val_loss: 123.2158\n",
            "Epoch 586/1000\n",
            "23/23 - 0s - loss: 7.8715 - val_loss: 125.5292\n",
            "Epoch 587/1000\n",
            "23/23 - 0s - loss: 8.4142 - val_loss: 121.6964\n",
            "Epoch 588/1000\n",
            "23/23 - 0s - loss: 8.1545 - val_loss: 114.5692\n",
            "Epoch 589/1000\n",
            "23/23 - 0s - loss: 8.2412 - val_loss: 121.8331\n",
            "Epoch 590/1000\n",
            "23/23 - 0s - loss: 8.3968 - val_loss: 122.4446\n",
            "Epoch 591/1000\n",
            "23/23 - 0s - loss: 8.0977 - val_loss: 125.2118\n",
            "Epoch 592/1000\n",
            "23/23 - 0s - loss: 8.1995 - val_loss: 120.6380\n",
            "Epoch 593/1000\n",
            "23/23 - 0s - loss: 8.3505 - val_loss: 119.6227\n",
            "Epoch 594/1000\n",
            "23/23 - 0s - loss: 7.8029 - val_loss: 122.7773\n",
            "Epoch 595/1000\n",
            "23/23 - 0s - loss: 8.0189 - val_loss: 122.4270\n",
            "Epoch 596/1000\n",
            "23/23 - 0s - loss: 8.1166 - val_loss: 110.0435\n",
            "Epoch 597/1000\n",
            "23/23 - 0s - loss: 7.8251 - val_loss: 116.8447\n",
            "Epoch 598/1000\n",
            "23/23 - 0s - loss: 7.9150 - val_loss: 123.9924\n",
            "Epoch 599/1000\n",
            "23/23 - 0s - loss: 7.9332 - val_loss: 123.1565\n",
            "Epoch 600/1000\n",
            "23/23 - 0s - loss: 7.9915 - val_loss: 123.6998\n",
            "Epoch 601/1000\n",
            "23/23 - 0s - loss: 7.7894 - val_loss: 120.7769\n",
            "Epoch 602/1000\n",
            "23/23 - 0s - loss: 8.0586 - val_loss: 121.0503\n",
            "Epoch 603/1000\n",
            "23/23 - 0s - loss: 7.7999 - val_loss: 117.5002\n",
            "Epoch 604/1000\n",
            "23/23 - 0s - loss: 7.7979 - val_loss: 126.1782\n",
            "Epoch 605/1000\n",
            "23/23 - 0s - loss: 7.7551 - val_loss: 121.6913\n",
            "Epoch 606/1000\n",
            "23/23 - 0s - loss: 8.2875 - val_loss: 118.7490\n",
            "Epoch 607/1000\n",
            "23/23 - 0s - loss: 7.9189 - val_loss: 117.3678\n",
            "Epoch 608/1000\n",
            "23/23 - 0s - loss: 8.0092 - val_loss: 124.3835\n",
            "Epoch 609/1000\n",
            "23/23 - 0s - loss: 7.7349 - val_loss: 120.9887\n",
            "Epoch 610/1000\n",
            "23/23 - 0s - loss: 7.6714 - val_loss: 125.4178\n",
            "Epoch 611/1000\n",
            "23/23 - 0s - loss: 7.8245 - val_loss: 120.9974\n",
            "Epoch 612/1000\n",
            "23/23 - 0s - loss: 7.7548 - val_loss: 118.3856\n",
            "Epoch 613/1000\n",
            "23/23 - 0s - loss: 8.0222 - val_loss: 125.2583\n",
            "Epoch 614/1000\n",
            "23/23 - 0s - loss: 7.8640 - val_loss: 117.6359\n",
            "Epoch 615/1000\n",
            "23/23 - 0s - loss: 7.6428 - val_loss: 118.8464\n",
            "Epoch 616/1000\n",
            "23/23 - 0s - loss: 7.8886 - val_loss: 124.2975\n",
            "Epoch 617/1000\n",
            "23/23 - 0s - loss: 7.5962 - val_loss: 120.6035\n",
            "Epoch 618/1000\n",
            "23/23 - 0s - loss: 7.6978 - val_loss: 121.3284\n",
            "Epoch 619/1000\n",
            "23/23 - 0s - loss: 7.6759 - val_loss: 118.1680\n",
            "Epoch 620/1000\n",
            "23/23 - 0s - loss: 8.2952 - val_loss: 118.2998\n",
            "Epoch 621/1000\n",
            "23/23 - 0s - loss: 8.2347 - val_loss: 121.6724\n",
            "Epoch 622/1000\n",
            "23/23 - 0s - loss: 8.0242 - val_loss: 122.8662\n",
            "Epoch 623/1000\n",
            "23/23 - 0s - loss: 7.7353 - val_loss: 123.6687\n",
            "Epoch 624/1000\n",
            "23/23 - 0s - loss: 7.7035 - val_loss: 125.4041\n",
            "Epoch 625/1000\n",
            "23/23 - 0s - loss: 8.0230 - val_loss: 121.4482\n",
            "Epoch 626/1000\n",
            "23/23 - 0s - loss: 7.5126 - val_loss: 121.2295\n",
            "Epoch 627/1000\n",
            "23/23 - 0s - loss: 7.5664 - val_loss: 124.4316\n",
            "Epoch 628/1000\n",
            "23/23 - 0s - loss: 7.7078 - val_loss: 114.6227\n",
            "Epoch 629/1000\n",
            "23/23 - 0s - loss: 8.4695 - val_loss: 114.8952\n",
            "Epoch 630/1000\n",
            "23/23 - 0s - loss: 7.7380 - val_loss: 121.8728\n",
            "Epoch 631/1000\n",
            "23/23 - 0s - loss: 7.6035 - val_loss: 121.6119\n",
            "Epoch 632/1000\n",
            "23/23 - 0s - loss: 7.7401 - val_loss: 125.4029\n",
            "Epoch 633/1000\n",
            "23/23 - 0s - loss: 7.7953 - val_loss: 116.5020\n",
            "Epoch 634/1000\n",
            "23/23 - 0s - loss: 8.0269 - val_loss: 123.5816\n",
            "Epoch 635/1000\n",
            "23/23 - 0s - loss: 7.7793 - val_loss: 124.1767\n",
            "Epoch 636/1000\n",
            "23/23 - 0s - loss: 7.7513 - val_loss: 120.3813\n",
            "Epoch 637/1000\n",
            "23/23 - 0s - loss: 7.7225 - val_loss: 121.8929\n",
            "Epoch 638/1000\n",
            "23/23 - 0s - loss: 7.6582 - val_loss: 116.9001\n",
            "Epoch 639/1000\n",
            "23/23 - 0s - loss: 8.4112 - val_loss: 125.1739\n",
            "Epoch 640/1000\n",
            "23/23 - 0s - loss: 7.6671 - val_loss: 113.4061\n",
            "Epoch 641/1000\n",
            "23/23 - 0s - loss: 7.7247 - val_loss: 118.6034\n",
            "Epoch 642/1000\n",
            "23/23 - 0s - loss: 8.3478 - val_loss: 123.2802\n",
            "Epoch 643/1000\n",
            "23/23 - 0s - loss: 7.7146 - val_loss: 124.8649\n",
            "Epoch 644/1000\n",
            "23/23 - 0s - loss: 7.4475 - val_loss: 123.8009\n",
            "Epoch 645/1000\n",
            "23/23 - 0s - loss: 7.5408 - val_loss: 124.7076\n",
            "Epoch 646/1000\n",
            "23/23 - 0s - loss: 7.6346 - val_loss: 122.3367\n",
            "Epoch 647/1000\n",
            "23/23 - 0s - loss: 7.4833 - val_loss: 118.3731\n",
            "Epoch 648/1000\n",
            "23/23 - 0s - loss: 7.4247 - val_loss: 121.3881\n",
            "Epoch 649/1000\n",
            "23/23 - 0s - loss: 7.5073 - val_loss: 118.3037\n",
            "Epoch 650/1000\n",
            "23/23 - 0s - loss: 7.4301 - val_loss: 122.7749\n",
            "Epoch 651/1000\n",
            "23/23 - 0s - loss: 7.6865 - val_loss: 121.7373\n",
            "Epoch 652/1000\n",
            "23/23 - 0s - loss: 7.6638 - val_loss: 123.9405\n",
            "Epoch 653/1000\n",
            "23/23 - 0s - loss: 7.5822 - val_loss: 118.9211\n",
            "Epoch 654/1000\n",
            "23/23 - 0s - loss: 8.0197 - val_loss: 123.2721\n",
            "Epoch 655/1000\n",
            "23/23 - 0s - loss: 7.7243 - val_loss: 123.9876\n",
            "Epoch 656/1000\n",
            "23/23 - 0s - loss: 7.4838 - val_loss: 116.5041\n",
            "Epoch 657/1000\n",
            "23/23 - 0s - loss: 7.8961 - val_loss: 129.7149\n",
            "Epoch 658/1000\n",
            "23/23 - 0s - loss: 7.5636 - val_loss: 119.0387\n",
            "Epoch 659/1000\n",
            "23/23 - 0s - loss: 7.5524 - val_loss: 118.4803\n",
            "Epoch 660/1000\n",
            "23/23 - 0s - loss: 8.1683 - val_loss: 122.1527\n",
            "Epoch 661/1000\n",
            "23/23 - 0s - loss: 7.6692 - val_loss: 123.1573\n",
            "Epoch 662/1000\n",
            "23/23 - 0s - loss: 7.4277 - val_loss: 113.1644\n",
            "Epoch 663/1000\n",
            "23/23 - 0s - loss: 8.2103 - val_loss: 124.9410\n",
            "Epoch 664/1000\n",
            "23/23 - 0s - loss: 7.3674 - val_loss: 127.7917\n",
            "Epoch 665/1000\n",
            "23/23 - 0s - loss: 8.0303 - val_loss: 126.3993\n",
            "Epoch 666/1000\n",
            "23/23 - 0s - loss: 7.9091 - val_loss: 118.9830\n",
            "Epoch 667/1000\n",
            "23/23 - 0s - loss: 7.5922 - val_loss: 115.5417\n",
            "Epoch 668/1000\n",
            "23/23 - 0s - loss: 7.7325 - val_loss: 119.7320\n",
            "Epoch 669/1000\n",
            "23/23 - 0s - loss: 7.5293 - val_loss: 118.9417\n",
            "Epoch 670/1000\n",
            "23/23 - 0s - loss: 8.1545 - val_loss: 128.9070\n",
            "Epoch 671/1000\n",
            "23/23 - 0s - loss: 8.0904 - val_loss: 121.5201\n",
            "Epoch 672/1000\n",
            "23/23 - 0s - loss: 8.1196 - val_loss: 122.1461\n",
            "Epoch 673/1000\n",
            "23/23 - 0s - loss: 7.2555 - val_loss: 115.5519\n",
            "Epoch 674/1000\n",
            "23/23 - 0s - loss: 8.6172 - val_loss: 127.4459\n",
            "Epoch 675/1000\n",
            "23/23 - 0s - loss: 7.7213 - val_loss: 117.1017\n",
            "Epoch 676/1000\n",
            "23/23 - 0s - loss: 8.1004 - val_loss: 126.2925\n",
            "Epoch 677/1000\n",
            "23/23 - 0s - loss: 7.7775 - val_loss: 114.3749\n",
            "Epoch 678/1000\n",
            "23/23 - 0s - loss: 7.6215 - val_loss: 124.7679\n",
            "Epoch 679/1000\n",
            "23/23 - 0s - loss: 7.3964 - val_loss: 123.6323\n",
            "Epoch 680/1000\n",
            "23/23 - 0s - loss: 7.5072 - val_loss: 120.6728\n",
            "Epoch 681/1000\n",
            "23/23 - 0s - loss: 7.6837 - val_loss: 117.5625\n",
            "Epoch 682/1000\n",
            "23/23 - 0s - loss: 7.4098 - val_loss: 118.3009\n",
            "Epoch 683/1000\n",
            "23/23 - 0s - loss: 7.4475 - val_loss: 123.2067\n",
            "Epoch 684/1000\n",
            "23/23 - 0s - loss: 7.8165 - val_loss: 118.3382\n",
            "Epoch 685/1000\n",
            "23/23 - 0s - loss: 7.3875 - val_loss: 121.5832\n",
            "Epoch 686/1000\n",
            "23/23 - 0s - loss: 7.5467 - val_loss: 120.6973\n",
            "Epoch 687/1000\n",
            "23/23 - 0s - loss: 7.2872 - val_loss: 123.9748\n",
            "Epoch 688/1000\n",
            "23/23 - 0s - loss: 7.3995 - val_loss: 125.9331\n",
            "Epoch 689/1000\n",
            "23/23 - 0s - loss: 7.3359 - val_loss: 120.8928\n",
            "Epoch 690/1000\n",
            "23/23 - 0s - loss: 8.0241 - val_loss: 120.9451\n",
            "Epoch 691/1000\n",
            "23/23 - 0s - loss: 7.5228 - val_loss: 126.2518\n",
            "Epoch 692/1000\n",
            "23/23 - 0s - loss: 7.5104 - val_loss: 129.6796\n",
            "Epoch 693/1000\n",
            "23/23 - 0s - loss: 7.4180 - val_loss: 122.0477\n",
            "Epoch 694/1000\n",
            "23/23 - 0s - loss: 7.1516 - val_loss: 116.8829\n",
            "Epoch 695/1000\n",
            "23/23 - 0s - loss: 7.5395 - val_loss: 117.8102\n",
            "Epoch 696/1000\n",
            "23/23 - 0s - loss: 7.3934 - val_loss: 121.4989\n",
            "Epoch 697/1000\n",
            "23/23 - 0s - loss: 7.3564 - val_loss: 123.1116\n",
            "Epoch 698/1000\n",
            "23/23 - 0s - loss: 7.5016 - val_loss: 119.9101\n",
            "Epoch 699/1000\n",
            "23/23 - 0s - loss: 7.3915 - val_loss: 121.8473\n",
            "Epoch 700/1000\n",
            "23/23 - 0s - loss: 7.9679 - val_loss: 125.8874\n",
            "Epoch 701/1000\n",
            "23/23 - 0s - loss: 7.7063 - val_loss: 123.8963\n",
            "Epoch 702/1000\n",
            "23/23 - 0s - loss: 7.2582 - val_loss: 126.5778\n",
            "Epoch 703/1000\n",
            "23/23 - 0s - loss: 7.4878 - val_loss: 129.8297\n",
            "Epoch 704/1000\n",
            "23/23 - 0s - loss: 7.4215 - val_loss: 123.4769\n",
            "Epoch 705/1000\n",
            "23/23 - 0s - loss: 7.6187 - val_loss: 130.0134\n",
            "Epoch 706/1000\n",
            "23/23 - 0s - loss: 8.1725 - val_loss: 119.3478\n",
            "Epoch 707/1000\n",
            "23/23 - 0s - loss: 8.0529 - val_loss: 125.0045\n",
            "Epoch 708/1000\n",
            "23/23 - 0s - loss: 7.3619 - val_loss: 123.3890\n",
            "Epoch 709/1000\n",
            "23/23 - 0s - loss: 7.4656 - val_loss: 128.6599\n",
            "Epoch 710/1000\n",
            "23/23 - 0s - loss: 7.3124 - val_loss: 124.1054\n",
            "Epoch 711/1000\n",
            "23/23 - 0s - loss: 7.4713 - val_loss: 119.6115\n",
            "Epoch 712/1000\n",
            "23/23 - 0s - loss: 7.5574 - val_loss: 123.6869\n",
            "Epoch 713/1000\n",
            "23/23 - 0s - loss: 7.3165 - val_loss: 122.8410\n",
            "Epoch 714/1000\n",
            "23/23 - 0s - loss: 7.5698 - val_loss: 124.0541\n",
            "Epoch 715/1000\n",
            "23/23 - 0s - loss: 7.4145 - val_loss: 120.0303\n",
            "Epoch 716/1000\n",
            "23/23 - 0s - loss: 7.1530 - val_loss: 122.0129\n",
            "Epoch 717/1000\n",
            "23/23 - 0s - loss: 7.6484 - val_loss: 123.6628\n",
            "Epoch 718/1000\n",
            "23/23 - 0s - loss: 7.4141 - val_loss: 128.3403\n",
            "Epoch 719/1000\n",
            "23/23 - 0s - loss: 7.1674 - val_loss: 126.4799\n",
            "Epoch 720/1000\n",
            "23/23 - 0s - loss: 7.3912 - val_loss: 126.7012\n",
            "Epoch 721/1000\n",
            "23/23 - 0s - loss: 7.6778 - val_loss: 126.4634\n",
            "Epoch 722/1000\n",
            "23/23 - 0s - loss: 7.6651 - val_loss: 117.4190\n",
            "Epoch 723/1000\n",
            "23/23 - 0s - loss: 7.4517 - val_loss: 122.9481\n",
            "Epoch 724/1000\n",
            "23/23 - 0s - loss: 6.9750 - val_loss: 120.2076\n",
            "Epoch 725/1000\n",
            "23/23 - 0s - loss: 7.5990 - val_loss: 126.3189\n",
            "Epoch 726/1000\n",
            "23/23 - 0s - loss: 8.1559 - val_loss: 124.5549\n",
            "Epoch 727/1000\n",
            "23/23 - 0s - loss: 7.4192 - val_loss: 118.2130\n",
            "Epoch 728/1000\n",
            "23/23 - 0s - loss: 7.2997 - val_loss: 124.8856\n",
            "Epoch 729/1000\n",
            "23/23 - 0s - loss: 7.3443 - val_loss: 126.0119\n",
            "Epoch 730/1000\n",
            "23/23 - 0s - loss: 7.3320 - val_loss: 126.8887\n",
            "Epoch 731/1000\n",
            "23/23 - 0s - loss: 7.3096 - val_loss: 122.9162\n",
            "Epoch 732/1000\n",
            "23/23 - 0s - loss: 7.2953 - val_loss: 124.7268\n",
            "Epoch 733/1000\n",
            "23/23 - 0s - loss: 7.6790 - val_loss: 129.1533\n",
            "Epoch 734/1000\n",
            "23/23 - 0s - loss: 7.3484 - val_loss: 120.9226\n",
            "Epoch 735/1000\n",
            "23/23 - 0s - loss: 7.4887 - val_loss: 117.8270\n",
            "Epoch 736/1000\n",
            "23/23 - 0s - loss: 7.3554 - val_loss: 131.1600\n",
            "Epoch 737/1000\n",
            "23/23 - 0s - loss: 7.4542 - val_loss: 121.8233\n",
            "Epoch 738/1000\n",
            "23/23 - 0s - loss: 7.2621 - val_loss: 123.4216\n",
            "Epoch 739/1000\n",
            "23/23 - 0s - loss: 7.2148 - val_loss: 120.9933\n",
            "Epoch 740/1000\n",
            "23/23 - 0s - loss: 7.1282 - val_loss: 125.7721\n",
            "Epoch 741/1000\n",
            "23/23 - 0s - loss: 7.1523 - val_loss: 125.3460\n",
            "Epoch 742/1000\n",
            "23/23 - 0s - loss: 7.5376 - val_loss: 127.0994\n",
            "Epoch 743/1000\n",
            "23/23 - 0s - loss: 7.5089 - val_loss: 127.7269\n",
            "Epoch 744/1000\n",
            "23/23 - 0s - loss: 7.3139 - val_loss: 119.8937\n",
            "Epoch 745/1000\n",
            "23/23 - 0s - loss: 7.3282 - val_loss: 130.4577\n",
            "Epoch 746/1000\n",
            "23/23 - 0s - loss: 7.2593 - val_loss: 118.9697\n",
            "Epoch 747/1000\n",
            "23/23 - 0s - loss: 7.0897 - val_loss: 126.1064\n",
            "Epoch 748/1000\n",
            "23/23 - 0s - loss: 7.0090 - val_loss: 125.8446\n",
            "Epoch 749/1000\n",
            "23/23 - 0s - loss: 7.3562 - val_loss: 124.0054\n",
            "Epoch 750/1000\n",
            "23/23 - 0s - loss: 7.4399 - val_loss: 131.6427\n",
            "Epoch 751/1000\n",
            "23/23 - 0s - loss: 7.1324 - val_loss: 125.3731\n",
            "Epoch 752/1000\n",
            "23/23 - 0s - loss: 7.1037 - val_loss: 123.4783\n",
            "Epoch 753/1000\n",
            "23/23 - 0s - loss: 7.1187 - val_loss: 123.5568\n",
            "Epoch 754/1000\n",
            "23/23 - 0s - loss: 7.0959 - val_loss: 121.6332\n",
            "Epoch 755/1000\n",
            "23/23 - 0s - loss: 7.0404 - val_loss: 119.9079\n",
            "Epoch 756/1000\n",
            "23/23 - 0s - loss: 7.1409 - val_loss: 128.2631\n",
            "Epoch 757/1000\n",
            "23/23 - 0s - loss: 7.1537 - val_loss: 121.7027\n",
            "Epoch 758/1000\n",
            "23/23 - 0s - loss: 7.0903 - val_loss: 117.6866\n",
            "Epoch 759/1000\n",
            "23/23 - 0s - loss: 7.2333 - val_loss: 127.4118\n",
            "Epoch 760/1000\n",
            "23/23 - 0s - loss: 7.1660 - val_loss: 122.4533\n",
            "Epoch 761/1000\n",
            "23/23 - 0s - loss: 7.2692 - val_loss: 122.8867\n",
            "Epoch 762/1000\n",
            "23/23 - 0s - loss: 7.6733 - val_loss: 124.0061\n",
            "Epoch 763/1000\n",
            "23/23 - 0s - loss: 7.2122 - val_loss: 124.8853\n",
            "Epoch 764/1000\n",
            "23/23 - 0s - loss: 7.2016 - val_loss: 124.3964\n",
            "Epoch 765/1000\n",
            "23/23 - 0s - loss: 7.6097 - val_loss: 125.4712\n",
            "Epoch 766/1000\n",
            "23/23 - 0s - loss: 7.5166 - val_loss: 129.4787\n",
            "Epoch 767/1000\n",
            "23/23 - 0s - loss: 7.1429 - val_loss: 124.7267\n",
            "Epoch 768/1000\n",
            "23/23 - 0s - loss: 6.9477 - val_loss: 125.5180\n",
            "Epoch 769/1000\n",
            "23/23 - 0s - loss: 7.3709 - val_loss: 131.8458\n",
            "Epoch 770/1000\n",
            "23/23 - 0s - loss: 7.4926 - val_loss: 131.9272\n",
            "Epoch 771/1000\n",
            "23/23 - 0s - loss: 7.4102 - val_loss: 122.9536\n",
            "Epoch 772/1000\n",
            "23/23 - 0s - loss: 7.1887 - val_loss: 119.8301\n",
            "Epoch 773/1000\n",
            "23/23 - 0s - loss: 7.2707 - val_loss: 129.4981\n",
            "Epoch 774/1000\n",
            "23/23 - 0s - loss: 7.6283 - val_loss: 121.4678\n",
            "Epoch 775/1000\n",
            "23/23 - 0s - loss: 7.2008 - val_loss: 123.7789\n",
            "Epoch 776/1000\n",
            "23/23 - 0s - loss: 7.6926 - val_loss: 128.3392\n",
            "Epoch 777/1000\n",
            "23/23 - 0s - loss: 7.3304 - val_loss: 131.3760\n",
            "Epoch 778/1000\n",
            "23/23 - 0s - loss: 6.9960 - val_loss: 126.0507\n",
            "Epoch 779/1000\n",
            "23/23 - 0s - loss: 7.0818 - val_loss: 119.2494\n",
            "Epoch 780/1000\n",
            "23/23 - 0s - loss: 7.7293 - val_loss: 129.6360\n",
            "Epoch 781/1000\n",
            "23/23 - 0s - loss: 7.2735 - val_loss: 120.5512\n",
            "Epoch 782/1000\n",
            "23/23 - 0s - loss: 7.2194 - val_loss: 127.2282\n",
            "Epoch 783/1000\n",
            "23/23 - 0s - loss: 7.4332 - val_loss: 117.4422\n",
            "Epoch 784/1000\n",
            "23/23 - 0s - loss: 7.2816 - val_loss: 128.5488\n",
            "Epoch 785/1000\n",
            "23/23 - 0s - loss: 7.2042 - val_loss: 121.7295\n",
            "Epoch 786/1000\n",
            "23/23 - 0s - loss: 6.9889 - val_loss: 125.8518\n",
            "Epoch 787/1000\n",
            "23/23 - 0s - loss: 7.2847 - val_loss: 118.0922\n",
            "Epoch 788/1000\n",
            "23/23 - 0s - loss: 6.8633 - val_loss: 137.3136\n",
            "Epoch 789/1000\n",
            "23/23 - 0s - loss: 7.4289 - val_loss: 124.9544\n",
            "Epoch 790/1000\n",
            "23/23 - 0s - loss: 7.2618 - val_loss: 129.0472\n",
            "Epoch 791/1000\n",
            "23/23 - 0s - loss: 6.9394 - val_loss: 126.1806\n",
            "Epoch 792/1000\n",
            "23/23 - 0s - loss: 6.9162 - val_loss: 125.0078\n",
            "Epoch 793/1000\n",
            "23/23 - 0s - loss: 7.0198 - val_loss: 127.2445\n",
            "Epoch 794/1000\n",
            "23/23 - 0s - loss: 7.4151 - val_loss: 125.2985\n",
            "Epoch 795/1000\n",
            "23/23 - 0s - loss: 7.1362 - val_loss: 135.8289\n",
            "Epoch 796/1000\n",
            "23/23 - 0s - loss: 6.9904 - val_loss: 126.4934\n",
            "Epoch 797/1000\n",
            "23/23 - 0s - loss: 7.0761 - val_loss: 124.4429\n",
            "Epoch 798/1000\n",
            "23/23 - 0s - loss: 6.8720 - val_loss: 128.7537\n",
            "Epoch 799/1000\n",
            "23/23 - 0s - loss: 6.9291 - val_loss: 122.9710\n",
            "Epoch 800/1000\n",
            "23/23 - 0s - loss: 7.0108 - val_loss: 122.6338\n",
            "Epoch 801/1000\n",
            "23/23 - 0s - loss: 7.2853 - val_loss: 122.1239\n",
            "Epoch 802/1000\n",
            "23/23 - 0s - loss: 7.8547 - val_loss: 132.0128\n",
            "Epoch 803/1000\n",
            "23/23 - 0s - loss: 7.1057 - val_loss: 125.8133\n",
            "Epoch 804/1000\n",
            "23/23 - 0s - loss: 7.1108 - val_loss: 133.3447\n",
            "Epoch 805/1000\n",
            "23/23 - 0s - loss: 7.4098 - val_loss: 126.1339\n",
            "Epoch 806/1000\n",
            "23/23 - 0s - loss: 7.3136 - val_loss: 123.5311\n",
            "Epoch 807/1000\n",
            "23/23 - 0s - loss: 6.8534 - val_loss: 132.1287\n",
            "Epoch 808/1000\n",
            "23/23 - 0s - loss: 6.7553 - val_loss: 130.6940\n",
            "Epoch 809/1000\n",
            "23/23 - 0s - loss: 6.9088 - val_loss: 123.2432\n",
            "Epoch 810/1000\n",
            "23/23 - 0s - loss: 7.1962 - val_loss: 125.1225\n",
            "Epoch 811/1000\n",
            "23/23 - 0s - loss: 7.3285 - val_loss: 125.3353\n",
            "Epoch 812/1000\n",
            "23/23 - 0s - loss: 6.8785 - val_loss: 127.3045\n",
            "Epoch 813/1000\n",
            "23/23 - 0s - loss: 7.1363 - val_loss: 126.8420\n",
            "Epoch 814/1000\n",
            "23/23 - 0s - loss: 7.6636 - val_loss: 135.9483\n",
            "Epoch 815/1000\n",
            "23/23 - 0s - loss: 6.9360 - val_loss: 126.4661\n",
            "Epoch 816/1000\n",
            "23/23 - 0s - loss: 6.9719 - val_loss: 129.1721\n",
            "Epoch 817/1000\n",
            "23/23 - 0s - loss: 7.2975 - val_loss: 126.8350\n",
            "Epoch 818/1000\n",
            "23/23 - 0s - loss: 7.0249 - val_loss: 128.9111\n",
            "Epoch 819/1000\n",
            "23/23 - 0s - loss: 7.0238 - val_loss: 125.0267\n",
            "Epoch 820/1000\n",
            "23/23 - 0s - loss: 7.0229 - val_loss: 121.7519\n",
            "Epoch 821/1000\n",
            "23/23 - 0s - loss: 7.1125 - val_loss: 123.1437\n",
            "Epoch 822/1000\n",
            "23/23 - 0s - loss: 6.8446 - val_loss: 127.6354\n",
            "Epoch 823/1000\n",
            "23/23 - 0s - loss: 7.4617 - val_loss: 123.4173\n",
            "Epoch 824/1000\n",
            "23/23 - 0s - loss: 6.9744 - val_loss: 130.6768\n",
            "Epoch 825/1000\n",
            "23/23 - 0s - loss: 6.8282 - val_loss: 127.4133\n",
            "Epoch 826/1000\n",
            "23/23 - 0s - loss: 6.9677 - val_loss: 131.9529\n",
            "Epoch 827/1000\n",
            "23/23 - 0s - loss: 7.2632 - val_loss: 125.1284\n",
            "Epoch 828/1000\n",
            "23/23 - 0s - loss: 6.9563 - val_loss: 131.5872\n",
            "Epoch 829/1000\n",
            "23/23 - 0s - loss: 7.3063 - val_loss: 134.9268\n",
            "Epoch 830/1000\n",
            "23/23 - 0s - loss: 7.1693 - val_loss: 125.8322\n",
            "Epoch 831/1000\n",
            "23/23 - 0s - loss: 6.7536 - val_loss: 131.3601\n",
            "Epoch 832/1000\n",
            "23/23 - 0s - loss: 6.8545 - val_loss: 124.7623\n",
            "Epoch 833/1000\n",
            "23/23 - 0s - loss: 6.7673 - val_loss: 128.7301\n",
            "Epoch 834/1000\n",
            "23/23 - 0s - loss: 7.0322 - val_loss: 122.7533\n",
            "Epoch 835/1000\n",
            "23/23 - 0s - loss: 7.3171 - val_loss: 125.2236\n",
            "Epoch 836/1000\n",
            "23/23 - 0s - loss: 6.8636 - val_loss: 121.3568\n",
            "Epoch 837/1000\n",
            "23/23 - 0s - loss: 6.8834 - val_loss: 132.4893\n",
            "Epoch 838/1000\n",
            "23/23 - 0s - loss: 7.2735 - val_loss: 126.3775\n",
            "Epoch 839/1000\n",
            "23/23 - 0s - loss: 6.7919 - val_loss: 121.7611\n",
            "Epoch 840/1000\n",
            "23/23 - 0s - loss: 7.5231 - val_loss: 127.3554\n",
            "Epoch 841/1000\n",
            "23/23 - 0s - loss: 7.1260 - val_loss: 130.8718\n",
            "Epoch 842/1000\n",
            "23/23 - 0s - loss: 6.9715 - val_loss: 128.3326\n",
            "Epoch 843/1000\n",
            "23/23 - 0s - loss: 6.9472 - val_loss: 130.9184\n",
            "Epoch 844/1000\n",
            "23/23 - 0s - loss: 7.3038 - val_loss: 130.7576\n",
            "Epoch 845/1000\n",
            "23/23 - 0s - loss: 6.9785 - val_loss: 124.0913\n",
            "Epoch 846/1000\n",
            "23/23 - 0s - loss: 7.3262 - val_loss: 127.1599\n",
            "Epoch 847/1000\n",
            "23/23 - 0s - loss: 7.1612 - val_loss: 125.7935\n",
            "Epoch 848/1000\n",
            "23/23 - 0s - loss: 7.0167 - val_loss: 128.8576\n",
            "Epoch 849/1000\n",
            "23/23 - 0s - loss: 7.0817 - val_loss: 132.4533\n",
            "Epoch 850/1000\n",
            "23/23 - 0s - loss: 6.9042 - val_loss: 126.0029\n",
            "Epoch 851/1000\n",
            "23/23 - 0s - loss: 6.9027 - val_loss: 133.0525\n",
            "Epoch 852/1000\n",
            "23/23 - 0s - loss: 6.9619 - val_loss: 125.0180\n",
            "Epoch 853/1000\n",
            "23/23 - 0s - loss: 6.8933 - val_loss: 132.8372\n",
            "Epoch 854/1000\n",
            "23/23 - 0s - loss: 7.0925 - val_loss: 133.5784\n",
            "Epoch 855/1000\n",
            "23/23 - 0s - loss: 7.1565 - val_loss: 128.2469\n",
            "Epoch 856/1000\n",
            "23/23 - 0s - loss: 6.8723 - val_loss: 130.4614\n",
            "Epoch 857/1000\n",
            "23/23 - 0s - loss: 7.3746 - val_loss: 125.8200\n",
            "Epoch 858/1000\n",
            "23/23 - 0s - loss: 7.2704 - val_loss: 125.4258\n",
            "Epoch 859/1000\n",
            "23/23 - 0s - loss: 7.1466 - val_loss: 129.1702\n",
            "Epoch 860/1000\n",
            "23/23 - 0s - loss: 7.2497 - val_loss: 130.8404\n",
            "Epoch 861/1000\n",
            "23/23 - 0s - loss: 7.1517 - val_loss: 125.4216\n",
            "Epoch 862/1000\n",
            "23/23 - 0s - loss: 7.8474 - val_loss: 124.7543\n",
            "Epoch 863/1000\n",
            "23/23 - 0s - loss: 6.7759 - val_loss: 118.9158\n",
            "Epoch 864/1000\n",
            "23/23 - 0s - loss: 7.6953 - val_loss: 122.4171\n",
            "Epoch 865/1000\n",
            "23/23 - 0s - loss: 6.9159 - val_loss: 135.8232\n",
            "Epoch 866/1000\n",
            "23/23 - 0s - loss: 6.9640 - val_loss: 127.1245\n",
            "Epoch 867/1000\n",
            "23/23 - 0s - loss: 7.0026 - val_loss: 129.4732\n",
            "Epoch 868/1000\n",
            "23/23 - 0s - loss: 7.1193 - val_loss: 129.1402\n",
            "Epoch 869/1000\n",
            "23/23 - 0s - loss: 7.2016 - val_loss: 121.4409\n",
            "Epoch 870/1000\n",
            "23/23 - 0s - loss: 7.4690 - val_loss: 123.6663\n",
            "Epoch 871/1000\n",
            "23/23 - 0s - loss: 6.8421 - val_loss: 136.7943\n",
            "Epoch 872/1000\n",
            "23/23 - 0s - loss: 7.0052 - val_loss: 127.8196\n",
            "Epoch 873/1000\n",
            "23/23 - 0s - loss: 6.9295 - val_loss: 127.6297\n",
            "Epoch 874/1000\n",
            "23/23 - 0s - loss: 7.1034 - val_loss: 141.4306\n",
            "Epoch 875/1000\n",
            "23/23 - 0s - loss: 6.8245 - val_loss: 124.7717\n",
            "Epoch 876/1000\n",
            "23/23 - 0s - loss: 6.7413 - val_loss: 124.8184\n",
            "Epoch 877/1000\n",
            "23/23 - 0s - loss: 6.9772 - val_loss: 136.2186\n",
            "Epoch 878/1000\n",
            "23/23 - 0s - loss: 6.8409 - val_loss: 120.3615\n",
            "Epoch 879/1000\n",
            "23/23 - 0s - loss: 7.4634 - val_loss: 125.2564\n",
            "Epoch 880/1000\n",
            "23/23 - 0s - loss: 6.7697 - val_loss: 126.1054\n",
            "Epoch 881/1000\n",
            "23/23 - 0s - loss: 6.7891 - val_loss: 130.9398\n",
            "Epoch 882/1000\n",
            "23/23 - 0s - loss: 6.7645 - val_loss: 125.1798\n",
            "Epoch 883/1000\n",
            "23/23 - 0s - loss: 6.9505 - val_loss: 135.2803\n",
            "Epoch 884/1000\n",
            "23/23 - 0s - loss: 7.3905 - val_loss: 131.8521\n",
            "Epoch 885/1000\n",
            "23/23 - 0s - loss: 7.8449 - val_loss: 125.6511\n",
            "Epoch 886/1000\n",
            "23/23 - 0s - loss: 6.8409 - val_loss: 125.4336\n",
            "Epoch 887/1000\n",
            "23/23 - 0s - loss: 6.8189 - val_loss: 125.8484\n",
            "Epoch 888/1000\n",
            "23/23 - 0s - loss: 6.9652 - val_loss: 134.1356\n",
            "Epoch 889/1000\n",
            "23/23 - 0s - loss: 6.5885 - val_loss: 128.3912\n",
            "Epoch 890/1000\n",
            "23/23 - 0s - loss: 6.8551 - val_loss: 129.4033\n",
            "Epoch 891/1000\n",
            "23/23 - 0s - loss: 6.6627 - val_loss: 123.4090\n",
            "Epoch 892/1000\n",
            "23/23 - 0s - loss: 6.7490 - val_loss: 127.9762\n",
            "Epoch 893/1000\n",
            "23/23 - 0s - loss: 6.5797 - val_loss: 126.6659\n",
            "Epoch 894/1000\n",
            "23/23 - 0s - loss: 6.7890 - val_loss: 123.9792\n",
            "Epoch 895/1000\n",
            "23/23 - 0s - loss: 6.9941 - val_loss: 127.9653\n",
            "Epoch 896/1000\n",
            "23/23 - 0s - loss: 6.7904 - val_loss: 128.8447\n",
            "Epoch 897/1000\n",
            "23/23 - 0s - loss: 6.5686 - val_loss: 123.5553\n",
            "Epoch 898/1000\n",
            "23/23 - 0s - loss: 7.0051 - val_loss: 129.8516\n",
            "Epoch 899/1000\n",
            "23/23 - 0s - loss: 6.6814 - val_loss: 130.8471\n",
            "Epoch 900/1000\n",
            "23/23 - 0s - loss: 6.7574 - val_loss: 122.9459\n",
            "Epoch 901/1000\n",
            "23/23 - 0s - loss: 7.4749 - val_loss: 129.8218\n",
            "Epoch 902/1000\n",
            "23/23 - 0s - loss: 7.1458 - val_loss: 119.7563\n",
            "Epoch 903/1000\n",
            "23/23 - 0s - loss: 7.0079 - val_loss: 131.2202\n",
            "Epoch 904/1000\n",
            "23/23 - 0s - loss: 6.6273 - val_loss: 126.0095\n",
            "Epoch 905/1000\n",
            "23/23 - 0s - loss: 6.7115 - val_loss: 119.4720\n",
            "Epoch 906/1000\n",
            "23/23 - 0s - loss: 7.3046 - val_loss: 121.8711\n",
            "Epoch 907/1000\n",
            "23/23 - 0s - loss: 6.9069 - val_loss: 130.1440\n",
            "Epoch 908/1000\n",
            "23/23 - 0s - loss: 6.8214 - val_loss: 132.8517\n",
            "Epoch 909/1000\n",
            "23/23 - 0s - loss: 7.2677 - val_loss: 131.1800\n",
            "Epoch 910/1000\n",
            "23/23 - 0s - loss: 6.8952 - val_loss: 130.1253\n",
            "Epoch 911/1000\n",
            "23/23 - 0s - loss: 6.7759 - val_loss: 134.9974\n",
            "Epoch 912/1000\n",
            "23/23 - 0s - loss: 6.5004 - val_loss: 128.5975\n",
            "Epoch 913/1000\n",
            "23/23 - 0s - loss: 6.6001 - val_loss: 125.9632\n",
            "Epoch 914/1000\n",
            "23/23 - 0s - loss: 6.5551 - val_loss: 131.4904\n",
            "Epoch 915/1000\n",
            "23/23 - 0s - loss: 7.4235 - val_loss: 127.9830\n",
            "Epoch 916/1000\n",
            "23/23 - 0s - loss: 7.0645 - val_loss: 125.1351\n",
            "Epoch 917/1000\n",
            "23/23 - 0s - loss: 6.8035 - val_loss: 125.3512\n",
            "Epoch 918/1000\n",
            "23/23 - 0s - loss: 6.6832 - val_loss: 131.4672\n",
            "Epoch 919/1000\n",
            "23/23 - 0s - loss: 6.7008 - val_loss: 127.7888\n",
            "Epoch 920/1000\n",
            "23/23 - 0s - loss: 6.7677 - val_loss: 129.6708\n",
            "Epoch 921/1000\n",
            "23/23 - 0s - loss: 6.4936 - val_loss: 130.4312\n",
            "Epoch 922/1000\n",
            "23/23 - 0s - loss: 7.0651 - val_loss: 124.2565\n",
            "Epoch 923/1000\n",
            "23/23 - 0s - loss: 6.6925 - val_loss: 128.2031\n",
            "Epoch 924/1000\n",
            "23/23 - 0s - loss: 7.1231 - val_loss: 135.2765\n",
            "Epoch 925/1000\n",
            "23/23 - 0s - loss: 6.8462 - val_loss: 133.5312\n",
            "Epoch 926/1000\n",
            "23/23 - 0s - loss: 7.0852 - val_loss: 124.9265\n",
            "Epoch 927/1000\n",
            "23/23 - 0s - loss: 6.8333 - val_loss: 126.4380\n",
            "Epoch 928/1000\n",
            "23/23 - 0s - loss: 6.8793 - val_loss: 129.9533\n",
            "Epoch 929/1000\n",
            "23/23 - 0s - loss: 7.1458 - val_loss: 131.0594\n",
            "Epoch 930/1000\n",
            "23/23 - 0s - loss: 6.9499 - val_loss: 133.3026\n",
            "Epoch 931/1000\n",
            "23/23 - 0s - loss: 6.6975 - val_loss: 126.1806\n",
            "Epoch 932/1000\n",
            "23/23 - 0s - loss: 6.6007 - val_loss: 130.2162\n",
            "Epoch 933/1000\n",
            "23/23 - 0s - loss: 6.4711 - val_loss: 126.8543\n",
            "Epoch 934/1000\n",
            "23/23 - 0s - loss: 7.0602 - val_loss: 129.2070\n",
            "Epoch 935/1000\n",
            "23/23 - 0s - loss: 6.4998 - val_loss: 128.6664\n",
            "Epoch 936/1000\n",
            "23/23 - 0s - loss: 6.6352 - val_loss: 133.5356\n",
            "Epoch 937/1000\n",
            "23/23 - 0s - loss: 6.5881 - val_loss: 127.0551\n",
            "Epoch 938/1000\n",
            "23/23 - 0s - loss: 7.0559 - val_loss: 130.9744\n",
            "Epoch 939/1000\n",
            "23/23 - 0s - loss: 6.5578 - val_loss: 133.2055\n",
            "Epoch 940/1000\n",
            "23/23 - 0s - loss: 7.1453 - val_loss: 128.9238\n",
            "Epoch 941/1000\n",
            "23/23 - 0s - loss: 6.5543 - val_loss: 129.9585\n",
            "Epoch 942/1000\n",
            "23/23 - 0s - loss: 6.8192 - val_loss: 131.0777\n",
            "Epoch 943/1000\n",
            "23/23 - 0s - loss: 6.4339 - val_loss: 128.3996\n",
            "Epoch 944/1000\n",
            "23/23 - 0s - loss: 6.4724 - val_loss: 130.2645\n",
            "Epoch 945/1000\n",
            "23/23 - 0s - loss: 6.5132 - val_loss: 134.6235\n",
            "Epoch 946/1000\n",
            "23/23 - 0s - loss: 7.1314 - val_loss: 125.9937\n",
            "Epoch 947/1000\n",
            "23/23 - 0s - loss: 6.5794 - val_loss: 128.7217\n",
            "Epoch 948/1000\n",
            "23/23 - 0s - loss: 6.8729 - val_loss: 123.4552\n",
            "Epoch 949/1000\n",
            "23/23 - 0s - loss: 6.5034 - val_loss: 129.4553\n",
            "Epoch 950/1000\n",
            "23/23 - 0s - loss: 6.4679 - val_loss: 121.9235\n",
            "Epoch 951/1000\n",
            "23/23 - 0s - loss: 6.6299 - val_loss: 126.6566\n",
            "Epoch 952/1000\n",
            "23/23 - 0s - loss: 6.6268 - val_loss: 122.8726\n",
            "Epoch 953/1000\n",
            "23/23 - 0s - loss: 7.2234 - val_loss: 125.2786\n",
            "Epoch 954/1000\n",
            "23/23 - 0s - loss: 7.5066 - val_loss: 126.9218\n",
            "Epoch 955/1000\n",
            "23/23 - 0s - loss: 7.1367 - val_loss: 124.7579\n",
            "Epoch 956/1000\n",
            "23/23 - 0s - loss: 6.8819 - val_loss: 125.7025\n",
            "Epoch 957/1000\n",
            "23/23 - 0s - loss: 6.6593 - val_loss: 132.0365\n",
            "Epoch 958/1000\n",
            "23/23 - 0s - loss: 6.6950 - val_loss: 129.5522\n",
            "Epoch 959/1000\n",
            "23/23 - 0s - loss: 6.6405 - val_loss: 123.7647\n",
            "Epoch 960/1000\n",
            "23/23 - 0s - loss: 6.7316 - val_loss: 126.7108\n",
            "Epoch 961/1000\n",
            "23/23 - 0s - loss: 6.7862 - val_loss: 123.7447\n",
            "Epoch 962/1000\n",
            "23/23 - 0s - loss: 7.4144 - val_loss: 140.7193\n",
            "Epoch 963/1000\n",
            "23/23 - 0s - loss: 6.7741 - val_loss: 122.8508\n",
            "Epoch 964/1000\n",
            "23/23 - 0s - loss: 6.8975 - val_loss: 131.5703\n",
            "Epoch 965/1000\n",
            "23/23 - 0s - loss: 6.7034 - val_loss: 130.7256\n",
            "Epoch 966/1000\n",
            "23/23 - 0s - loss: 6.8129 - val_loss: 127.0102\n",
            "Epoch 967/1000\n",
            "23/23 - 0s - loss: 6.4324 - val_loss: 132.2609\n",
            "Epoch 968/1000\n",
            "23/23 - 0s - loss: 6.4768 - val_loss: 122.8250\n",
            "Epoch 969/1000\n",
            "23/23 - 0s - loss: 6.6320 - val_loss: 126.6881\n",
            "Epoch 970/1000\n",
            "23/23 - 0s - loss: 6.7482 - val_loss: 130.5038\n",
            "Epoch 971/1000\n",
            "23/23 - 0s - loss: 6.8939 - val_loss: 126.0443\n",
            "Epoch 972/1000\n",
            "23/23 - 0s - loss: 6.8507 - val_loss: 124.3432\n",
            "Epoch 973/1000\n",
            "23/23 - 0s - loss: 6.6634 - val_loss: 127.8353\n",
            "Epoch 974/1000\n",
            "23/23 - 0s - loss: 6.6078 - val_loss: 132.7962\n",
            "Epoch 975/1000\n",
            "23/23 - 0s - loss: 6.6296 - val_loss: 133.7283\n",
            "Epoch 976/1000\n",
            "23/23 - 0s - loss: 7.1347 - val_loss: 137.6402\n",
            "Epoch 977/1000\n",
            "23/23 - 0s - loss: 6.6797 - val_loss: 129.1360\n",
            "Epoch 978/1000\n",
            "23/23 - 0s - loss: 6.4613 - val_loss: 134.8448\n",
            "Epoch 979/1000\n",
            "23/23 - 0s - loss: 6.4705 - val_loss: 131.7410\n",
            "Epoch 980/1000\n",
            "23/23 - 0s - loss: 6.4994 - val_loss: 124.2289\n",
            "Epoch 981/1000\n",
            "23/23 - 0s - loss: 6.8945 - val_loss: 128.6466\n",
            "Epoch 982/1000\n",
            "23/23 - 0s - loss: 6.6868 - val_loss: 132.2697\n",
            "Epoch 983/1000\n",
            "23/23 - 0s - loss: 6.9160 - val_loss: 128.0756\n",
            "Epoch 984/1000\n",
            "23/23 - 0s - loss: 6.3768 - val_loss: 128.1019\n",
            "Epoch 985/1000\n",
            "23/23 - 0s - loss: 6.4804 - val_loss: 128.5512\n",
            "Epoch 986/1000\n",
            "23/23 - 0s - loss: 6.5313 - val_loss: 128.4293\n",
            "Epoch 987/1000\n",
            "23/23 - 0s - loss: 6.5744 - val_loss: 120.3271\n",
            "Epoch 988/1000\n",
            "23/23 - 0s - loss: 6.9402 - val_loss: 134.6039\n",
            "Epoch 989/1000\n",
            "23/23 - 0s - loss: 6.7860 - val_loss: 132.8532\n",
            "Epoch 990/1000\n",
            "23/23 - 0s - loss: 6.7932 - val_loss: 126.5930\n",
            "Epoch 991/1000\n",
            "23/23 - 0s - loss: 6.4386 - val_loss: 130.0734\n",
            "Epoch 992/1000\n",
            "23/23 - 0s - loss: 6.8074 - val_loss: 134.4772\n",
            "Epoch 993/1000\n",
            "23/23 - 0s - loss: 6.4880 - val_loss: 125.9488\n",
            "Epoch 994/1000\n",
            "23/23 - 0s - loss: 6.5949 - val_loss: 135.2455\n",
            "Epoch 995/1000\n",
            "23/23 - 0s - loss: 7.1919 - val_loss: 127.7132\n",
            "Epoch 996/1000\n",
            "23/23 - 0s - loss: 7.0697 - val_loss: 131.7993\n",
            "Epoch 997/1000\n",
            "23/23 - 0s - loss: 6.4933 - val_loss: 131.4431\n",
            "Epoch 998/1000\n",
            "23/23 - 0s - loss: 6.8723 - val_loss: 126.7161\n",
            "Epoch 999/1000\n",
            "23/23 - 0s - loss: 6.7919 - val_loss: 127.2952\n",
            "Epoch 1000/1000\n",
            "23/23 - 0s - loss: 7.2389 - val_loss: 140.7711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e17989490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}